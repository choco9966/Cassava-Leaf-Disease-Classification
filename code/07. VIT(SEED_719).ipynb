{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 2.173722,
     "end_time": "2020-11-23T13:32:49.521795",
     "exception": false,
     "start_time": "2020-11-23T13:32:47.348073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "import cv2\n",
    "from skimage import io\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from adamp import AdamP\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import timm\n",
    "\n",
    "import sklearn\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import cv2\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "from scipy.ndimage.interpolation import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.026635,
     "end_time": "2020-11-23T13:32:49.570638",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.544003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 719,\n",
    "    'model_arch': 'vit_base_patch16_384',\n",
    "    'model_path': 'vit_11ep',\n",
    "    'img_size': 384,\n",
    "    'epochs': 11,\n",
    "    'train_bs': 8,\n",
    "    'valid_bs': 8,\n",
    "    'T_0': 10,\n",
    "    'lr': 1e-4,\n",
    "    'min_lr': 1e-6,\n",
    "    'weight_decay':1e-6,\n",
    "    'freeze_bn_epochs': 5,\n",
    "    'num_workers': 0,\n",
    "    'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "    'verbose_step': 1,\n",
    "    'device': 'cuda:0',\n",
    "    'target_size' : 5, \n",
    "    'smoothing' : 0.3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(CFG['model_path']):\n",
    "    os.makedirs(CFG['model_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "papermill": {
     "duration": 0.057123,
     "end_time": "2020-11-23T13:32:49.643710",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.586587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  1000015157.jpg      0\n",
       "1  1000201771.jpg      3\n",
       "2   100042118.jpg      1\n",
       "3  1000723321.jpg      1\n",
       "4  1000812911.jpg      3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./cassava-leaf-disease-classification/modified_train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.028528,
     "end_time": "2020-11-23T13:32:49.688153",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.659625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    13192\n",
       "4     2553\n",
       "2     2374\n",
       "1     2186\n",
       "0     1089\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016085,
     "end_time": "2020-11-23T13:32:49.720073",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.703988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> We could do stratified validation split in each fold to make each fold's train and validation set looks like the whole train set in target distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.032053,
     "end_time": "2020-11-23T13:32:49.768481",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.736428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  2216849948.jpg      4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('./cassava-leaf-disease-classification/sample_submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015931,
     "end_time": "2020-11-23T13:32:49.801027",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.785096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.315262,
     "end_time": "2020-11-23T13:32:50.132792",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.817530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    #print(im_rgb)\n",
    "    return im_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021311,
     "end_time": "2020-11-23T13:32:50.174973",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.153662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.064816,
     "end_time": "2020-11-23T13:32:50.261340",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.196524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[0]\n",
    "    H = size[1]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, df, data_root, \n",
    "                 transforms=None, \n",
    "                 output_label=True, \n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transforms = transforms\n",
    "        self.data_root = data_root\n",
    "        \n",
    "        self.output_label = output_label\n",
    "        self.labels = self.df['label'].values\n",
    "\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # get labels\n",
    "        if self.output_label:\n",
    "            target = self.labels[index]\n",
    "          \n",
    "        img  = get_img(\"{}/{}\".format(self.data_root, self.df.loc[index]['image_id']))\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "        \n",
    "        if self.output_label == True:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02183,
     "end_time": "2020-11-23T13:32:50.304795",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.282965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Train\\Validation Image Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations.core.transforms_interface import DualTransform\n",
    "from albumentations.augmentations import functional as F\n",
    "class GridMask(DualTransform):\n",
    "    \"\"\"GridMask augmentation for image classification and object detection.\n",
    "    \n",
    "    Author: Qishen Ha\n",
    "    Email: haqishen@gmail.com\n",
    "    2020/01/29\n",
    "\n",
    "    Args:\n",
    "        num_grid (int): number of grid in a row or column.\n",
    "        fill_value (int, float, lisf of int, list of float): value for dropped pixels.\n",
    "        rotate ((int, int) or int): range from which a random angle is picked. If rotate is a single int\n",
    "            an angle is picked from (-rotate, rotate). Default: (-90, 90)\n",
    "        mode (int):\n",
    "            0 - cropout a quarter of the square of each grid (left top)\n",
    "            1 - reserve a quarter of the square of each grid (left top)\n",
    "            2 - cropout 2 quarter of the square of each grid (left top & right bottom)\n",
    "\n",
    "    Targets:\n",
    "        image, mask\n",
    "\n",
    "    Image types:\n",
    "        uint8, float32\n",
    "\n",
    "    Reference:\n",
    "    |  https://arxiv.org/abs/2001.04086\n",
    "    |  https://github.com/akuxcw/GridMask\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_grid=3, fill_value=0, rotate=0, mode=0, always_apply=False, p=0.5):\n",
    "        super(GridMask, self).__init__(always_apply, p)\n",
    "        if isinstance(num_grid, int):\n",
    "            num_grid = (num_grid, num_grid)\n",
    "        if isinstance(rotate, int):\n",
    "            rotate = (-rotate, rotate)\n",
    "        self.num_grid = num_grid\n",
    "        self.fill_value = fill_value\n",
    "        self.rotate = rotate\n",
    "        self.mode = mode\n",
    "        self.masks = None\n",
    "        self.rand_h_max = []\n",
    "        self.rand_w_max = []\n",
    "\n",
    "    def init_masks(self, height, width):\n",
    "        if self.masks is None:\n",
    "            self.masks = []\n",
    "            n_masks = self.num_grid[1] - self.num_grid[0] + 1\n",
    "            for n, n_g in enumerate(range(self.num_grid[0], self.num_grid[1] + 1, 1)):\n",
    "                grid_h = height / n_g\n",
    "                grid_w = width / n_g\n",
    "                this_mask = np.ones((int((n_g + 1) * grid_h), int((n_g + 1) * grid_w))).astype(np.uint8)\n",
    "                for i in range(n_g + 1):\n",
    "                    for j in range(n_g + 1):\n",
    "                        this_mask[\n",
    "                             int(i * grid_h) : int(i * grid_h + grid_h / 2),\n",
    "                             int(j * grid_w) : int(j * grid_w + grid_w / 2)\n",
    "                        ] = self.fill_value\n",
    "                        if self.mode == 2:\n",
    "                            this_mask[\n",
    "                                 int(i * grid_h + grid_h / 2) : int(i * grid_h + grid_h),\n",
    "                                 int(j * grid_w + grid_w / 2) : int(j * grid_w + grid_w)\n",
    "                            ] = self.fill_value\n",
    "                \n",
    "                if self.mode == 1:\n",
    "                    this_mask = 1 - this_mask\n",
    "\n",
    "                self.masks.append(this_mask)\n",
    "                self.rand_h_max.append(grid_h)\n",
    "                self.rand_w_max.append(grid_w)\n",
    "\n",
    "    def apply(self, image, mask, rand_h, rand_w, angle, **params):\n",
    "        h, w = image.shape[:2]\n",
    "        mask = F.rotate(mask, angle) if self.rotate[1] > 0 else mask\n",
    "        mask = mask[:,:,np.newaxis] if image.ndim == 3 else mask\n",
    "        image *= mask[rand_h:rand_h+h, rand_w:rand_w+w].astype(image.dtype)\n",
    "        return image\n",
    "\n",
    "    def get_params_dependent_on_targets(self, params):\n",
    "        img = params['image']\n",
    "        height, width = img.shape[:2]\n",
    "        self.init_masks(height, width)\n",
    "\n",
    "        mid = np.random.randint(len(self.masks))\n",
    "        mask = self.masks[mid]\n",
    "        rand_h = np.random.randint(self.rand_h_max[mid])\n",
    "        rand_w = np.random.randint(self.rand_w_max[mid])\n",
    "        angle = np.random.randint(self.rotate[0], self.rotate[1]) if self.rotate[1] > 0 else 0\n",
    "\n",
    "        return {'mask': mask, 'rand_h': rand_h, 'rand_w': rand_w, 'angle': angle}\n",
    "\n",
    "    @property\n",
    "    def targets_as_params(self):\n",
    "        return ['image']\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return ('num_grid', 'fill_value', 'rotate', 'mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 0.590042,
     "end_time": "2020-11-23T13:32:50.916225",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.326183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize, Rotate\n",
    ")\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def get_train_transforms():\n",
    "    return Compose([\n",
    "            OneOf([\n",
    "                Resize(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "                CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "                RandomResizedCrop(CFG['img_size'], CFG['img_size'], p=1.)\n",
    "            ], p=1.), \n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            ShiftScaleRotate(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            CoarseDropout(p=0.5),\n",
    "            GridMask(num_grid=3, p=0.5),\n",
    "            Cutout(p=0.5),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "\n",
    "\n",
    "        \n",
    "def get_valid_transforms():\n",
    "    return Compose([\n",
    "            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "            Resize(CFG['img_size'], CFG['img_size']),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024452,
     "end_time": "2020-11-23T13:32:50.962106",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.937654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 0.033239,
     "end_time": "2020-11-23T13:32:51.017593",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.984354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, n_class)\n",
    "#         self.model.classifier = nn.Sequential(\n",
    "#             nn.Linear(n_features, n_features//2),\n",
    "#             nn.LeakyReLU(inplace=True),\n",
    "#             nn.Linear(n_features//2, n_class)\n",
    "#         )\n",
    "        \n",
    "        for module in self.model.modules():\n",
    "            #print(module)\n",
    "            if isinstance(module, nn.BatchNorm2d):\n",
    "                if hasattr(module, 'weight'):\n",
    "                    module.weight.requires_grad_(False)\n",
    "                if hasattr(module, 'bias'):\n",
    "                    module.bias.requires_grad_(False)\n",
    "                #module.eval()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassvaImgClassifier_ViT(nn.Module):\n",
    "    def __init__(self, model_arch, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        #if pretrained:\n",
    "        #    self.model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, n_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021054,
     "end_time": "2020-11-23T13:32:51.059722",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.038668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "papermill": {
     "duration": 0.061685,
     "end_time": "2020-11-23T13:32:51.144150",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.082465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_dataloader(df, trn_idx, val_idx, data_root='./cassava-leaf-disease-classification/train_images/'):\n",
    "    \n",
    "    # from catalyst.data.sampler import BalanceClassSampler\n",
    "    \n",
    "    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n",
    "    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n",
    "        \n",
    "    train_ds = CassavaDataset(train_, data_root, transforms=get_train_transforms(), output_label=True)\n",
    "    valid_ds = CassavaDataset(valid_, data_root, transforms=get_valid_transforms(), output_label=True)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        shuffle=True,        \n",
    "        num_workers=CFG['num_workers'],\n",
    "        #sampler=BalanceClassSampler(labels=train_['label'].values, mode=\"downsampling\")\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=CFG['valid_bs'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None, schd_batch_update=False):\n",
    "    #model.train()\n",
    "\n",
    "    t = time.time()\n",
    "    running_loss = None\n",
    "\n",
    "    # pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, image_labels) in enumerate(train_loader):\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "\n",
    "        with autocast():\n",
    "            image_preds = model(imgs)   #output = model(input)\n",
    "            loss = loss_fn(image_preds, image_labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if running_loss is None:\n",
    "                running_loss = loss.item()\n",
    "            else:\n",
    "                running_loss = running_loss * .99 + loss.item() * .01\n",
    "\n",
    "            if ((step + 1) %  CFG['accum_iter'] == 0) or ((step + 1) == len(train_loader)):\n",
    "\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad() \n",
    "                \n",
    "                if scheduler is not None and schd_batch_update:\n",
    "                    scheduler.step()\n",
    "\n",
    "            if step % 150 == 0:\n",
    "                print(f\"step : {step}/{len(train_loader)}, loss : {running_loss}\")\n",
    "            # if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "            #     description = f'epoch {epoch} loss: {running_loss:.4f}'\n",
    "            #     print(description)\n",
    "                # pbar.set_description(description)\n",
    "                \n",
    "    if scheduler is not None and not schd_batch_update:\n",
    "        scheduler.step()\n",
    "        \n",
    "def valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n",
    "    model.eval()\n",
    "\n",
    "    t = time.time()\n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    \n",
    "    # pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    for step, (imgs, image_labels) in enumerate(val_loader):\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "        loss = loss_fn(image_preds, image_labels)\n",
    "        \n",
    "        loss_sum += loss.item()*image_labels.shape[0]\n",
    "        sample_num += image_labels.shape[0]  \n",
    "\n",
    "        # if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(val_loader)):\n",
    "        #     description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n",
    "        #     pbar.set_description(description)\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    print('epoch = {}'.format(epoch+1), f'loss = {loss}', 'validation multi-class accuracy = {:.4f}'.format((image_preds_all==image_targets_all).mean()))\n",
    "    \n",
    "    if scheduler is not None:\n",
    "        if schd_loss_update:\n",
    "            scheduler.step(loss_sum/sample_num)\n",
    "        else:\n",
    "            scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_batchnorm_stats(net):\n",
    "    net.train()\n",
    "    try:\n",
    "        for m in net.modules():\n",
    "            if isinstance(m,nn.BatchNorm2d) or isinstance(m,nn.LayerNorm):\n",
    "                m.eval()\n",
    "    except ValuError:\n",
    "        print('error with batchnorm2d or layernorm')\n",
    "        return\n",
    "    \n",
    "def unfreeze_batchnorm_stats(net):\n",
    "    net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 0.034873,
     "end_time": "2020-11-23T13:32:51.200704",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.165831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    \"\"\"\n",
    "    NLL loss with label smoothing.\n",
    "    \"\"\"\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        \"\"\"\n",
    "        Constructor for the LabelSmoothing module.\n",
    "        :param smoothing: label smoothing factor\n",
    "        \"\"\"\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "        assert smoothing < 1.0\n",
    "        self.smoothing = smoothing\n",
    "        self.confidence = 1. - smoothing\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n",
    "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Label Smoothing\n",
    "# ====================================================\n",
    "class LabelSmoothingLoss(nn.Module): \n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1): \n",
    "        super(LabelSmoothingLoss, self).__init__() \n",
    "        self.confidence = 1.0 - smoothing \n",
    "        self.smoothing = smoothing \n",
    "        self.cls = classes \n",
    "        self.dim = dim \n",
    "        \n",
    "    def forward(self, pred, target): \n",
    "        pred = pred.log_softmax(dim=self.dim) \n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred) \n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1)) \n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence) \n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020806,
     "end_time": "2020-11-23T13:32:51.243006",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.222200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchcontrib.optim import SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # specify GPUs locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 0 started\n",
      "17115 4279\n",
      "step : 0/2140, loss : 1.7391633987426758\n",
      "step : 150/2140, loss : 1.3404999248017433\n",
      "step : 300/2140, loss : 1.189229542735612\n",
      "step : 450/2140, loss : 1.1358589703429047\n",
      "step : 600/2140, loss : 1.1034866658434324\n",
      "step : 750/2140, loss : 1.096895410618981\n",
      "step : 900/2140, loss : 1.1131728974957893\n",
      "step : 1050/2140, loss : 1.0820192719800767\n",
      "step : 1200/2140, loss : 1.0940038252947508\n",
      "step : 1350/2140, loss : 1.1007785122059355\n",
      "step : 1500/2140, loss : 1.0943938487857454\n",
      "step : 1650/2140, loss : 1.0792356199068192\n",
      "step : 1800/2140, loss : 1.091747277120292\n",
      "step : 1950/2140, loss : 1.0772261877226275\n",
      "step : 2100/2140, loss : 1.0568460865968317\n",
      "epoch = 1 loss = 0.587393581867218 validation multi-class accuracy = 0.8682\n",
      "step : 0/2140, loss : 1.1604325771331787\n",
      "step : 150/2140, loss : 1.0910452967954989\n",
      "step : 300/2140, loss : 1.0883585796249506\n",
      "step : 450/2140, loss : 1.0743605690369635\n",
      "step : 600/2140, loss : 1.1049268547582183\n",
      "step : 750/2140, loss : 1.0763714066592536\n",
      "step : 900/2140, loss : 1.0702530102266143\n",
      "step : 1050/2140, loss : 1.0528412993203544\n",
      "step : 1200/2140, loss : 1.0594714083281027\n",
      "step : 1350/2140, loss : 1.078018834131365\n",
      "step : 1500/2140, loss : 1.058759643456462\n",
      "step : 1650/2140, loss : 1.0686241620363672\n",
      "step : 1800/2140, loss : 1.0443490194243694\n",
      "step : 1950/2140, loss : 1.0591459493253075\n",
      "step : 2100/2140, loss : 1.0621412736837597\n",
      "epoch = 2 loss = 0.6161590218544006 validation multi-class accuracy = 0.8801\n",
      "step : 0/2140, loss : 1.0666086673736572\n",
      "step : 150/2140, loss : 1.0602610049650545\n",
      "step : 300/2140, loss : 1.035020204324499\n",
      "step : 450/2140, loss : 1.037300872041\n",
      "step : 600/2140, loss : 1.0690772199635281\n",
      "step : 750/2140, loss : 1.0715098790650142\n",
      "step : 900/2140, loss : 1.0684087654575802\n",
      "step : 1050/2140, loss : 1.0595108188852267\n",
      "step : 1200/2140, loss : 1.0641387676500003\n",
      "step : 1350/2140, loss : 1.0556083503204983\n",
      "step : 1500/2140, loss : 1.0489353353682063\n",
      "step : 1650/2140, loss : 1.0506642892365634\n",
      "step : 1800/2140, loss : 1.0536756745020366\n",
      "step : 1950/2140, loss : 1.0557987725095401\n",
      "step : 2100/2140, loss : 1.036931234539233\n",
      "epoch = 3 loss = 0.6298713088035583 validation multi-class accuracy = 0.8897\n",
      "step : 0/2140, loss : 0.988465428352356\n",
      "step : 150/2140, loss : 1.0333257463005994\n",
      "step : 300/2140, loss : 1.0348499980581967\n",
      "step : 450/2140, loss : 1.0468311367979615\n",
      "step : 600/2140, loss : 1.0473203895567713\n",
      "step : 750/2140, loss : 1.0519416448339582\n",
      "step : 900/2140, loss : 1.0441807871240647\n",
      "step : 1050/2140, loss : 1.0468028915113825\n",
      "step : 1200/2140, loss : 1.0310828348031456\n",
      "step : 1350/2140, loss : 1.0514552144894753\n",
      "step : 1500/2140, loss : 1.0335913471124298\n",
      "step : 1650/2140, loss : 1.0443300972443175\n",
      "step : 1800/2140, loss : 1.05474922737453\n",
      "step : 1950/2140, loss : 1.048785353950304\n",
      "step : 2100/2140, loss : 1.063729787245434\n",
      "epoch = 4 loss = 0.6972975134849548 validation multi-class accuracy = 0.8883\n",
      "step : 0/2140, loss : 1.224191665649414\n",
      "step : 150/2140, loss : 1.0793312803098694\n",
      "step : 300/2140, loss : 1.0343386635685596\n",
      "step : 450/2140, loss : 1.019915347260032\n",
      "step : 600/2140, loss : 1.0356731582389023\n",
      "step : 750/2140, loss : 1.0272741865073793\n",
      "step : 900/2140, loss : 1.0273671284280579\n",
      "step : 1050/2140, loss : 1.052159241535635\n",
      "step : 1200/2140, loss : 1.0436714336447934\n",
      "step : 1350/2140, loss : 1.0421877442275311\n",
      "step : 1500/2140, loss : 1.0440562018534159\n",
      "step : 1650/2140, loss : 1.0387796408666021\n",
      "step : 1800/2140, loss : 1.0603781155018512\n",
      "step : 1950/2140, loss : 1.0619665577740094\n",
      "step : 2100/2140, loss : 1.0487292024331487\n",
      "epoch = 5 loss = 0.6830360293388367 validation multi-class accuracy = 0.8778\n",
      "step : 0/2140, loss : 1.0736138820648193\n",
      "step : 150/2140, loss : 1.0254071541989962\n",
      "step : 300/2140, loss : 1.0493722141502324\n",
      "step : 450/2140, loss : 1.0215906719844816\n",
      "step : 600/2140, loss : 1.0152423617382524\n",
      "step : 750/2140, loss : 1.0373877994894878\n",
      "step : 900/2140, loss : 1.0476522559986197\n",
      "step : 1050/2140, loss : 1.0455631360108677\n",
      "step : 1200/2140, loss : 1.0240263769478983\n",
      "step : 1350/2140, loss : 1.046307279797608\n",
      "step : 1500/2140, loss : 1.0268881501974172\n",
      "step : 1650/2140, loss : 1.0131928770482852\n",
      "step : 1800/2140, loss : 1.0509966487843385\n",
      "step : 1950/2140, loss : 1.0437493227849273\n",
      "step : 2100/2140, loss : 1.0515401776459414\n",
      "epoch = 6 loss = 0.5814441442489624 validation multi-class accuracy = 0.8855\n",
      "step : 0/2140, loss : 0.978545069694519\n",
      "step : 150/2140, loss : 1.0115750686773461\n",
      "step : 300/2140, loss : 1.0264416059559478\n",
      "step : 450/2140, loss : 1.0272588537640095\n",
      "step : 600/2140, loss : 1.0265432068323246\n",
      "step : 750/2140, loss : 1.025184995364906\n",
      "step : 900/2140, loss : 1.0341217031938155\n",
      "step : 1050/2140, loss : 1.032675654472136\n",
      "step : 1200/2140, loss : 1.0255275305049365\n",
      "step : 1350/2140, loss : 1.0221029415221263\n",
      "step : 1500/2140, loss : 1.0421643416307007\n",
      "step : 1650/2140, loss : 1.0363201429774789\n",
      "step : 1800/2140, loss : 1.048812447953773\n",
      "step : 1950/2140, loss : 1.0310837723411783\n",
      "step : 2100/2140, loss : 1.0450727897866356\n",
      "epoch = 7 loss = 0.7633099555969238 validation multi-class accuracy = 0.8836\n",
      "step : 0/2140, loss : 0.937422513961792\n",
      "step : 150/2140, loss : 1.0117304539381453\n",
      "step : 300/2140, loss : 1.03761696153234\n",
      "step : 450/2140, loss : 1.0146141685660433\n",
      "step : 600/2140, loss : 1.0335224695482612\n",
      "step : 750/2140, loss : 1.0432601573023343\n",
      "step : 900/2140, loss : 1.021925904463896\n",
      "step : 1050/2140, loss : 1.0226236669458009\n",
      "step : 1200/2140, loss : 1.0276029588373423\n",
      "step : 1350/2140, loss : 1.0353895856253739\n",
      "step : 1500/2140, loss : 1.0366475638918355\n",
      "step : 1650/2140, loss : 1.0305471080440038\n",
      "step : 1800/2140, loss : 1.0183024948239574\n",
      "step : 1950/2140, loss : 1.0197724234796863\n",
      "step : 2100/2140, loss : 1.0198388322210181\n",
      "epoch = 8 loss = 0.5893465280532837 validation multi-class accuracy = 0.8878\n",
      "step : 0/2140, loss : 0.9511637687683105\n",
      "step : 150/2140, loss : 1.0227988631749096\n",
      "step : 300/2140, loss : 1.0090767830969951\n",
      "step : 450/2140, loss : 1.0155976902002077\n",
      "step : 600/2140, loss : 1.0188960757417587\n",
      "step : 750/2140, loss : 1.0204801486820012\n",
      "step : 900/2140, loss : 1.0251273745727416\n",
      "step : 1050/2140, loss : 1.0305715648721143\n",
      "step : 1200/2140, loss : 1.025272320357916\n",
      "step : 1350/2140, loss : 1.0209379451138139\n",
      "step : 1500/2140, loss : 1.0311486384617743\n",
      "step : 1650/2140, loss : 1.041576621498034\n",
      "step : 1800/2140, loss : 1.0291707925667324\n",
      "step : 1950/2140, loss : 1.016981231810451\n",
      "step : 2100/2140, loss : 1.0072868283811744\n",
      "epoch = 9 loss = 0.6154990792274475 validation multi-class accuracy = 0.8860\n",
      "step : 0/2140, loss : 0.9849995374679565\n",
      "step : 150/2140, loss : 0.9913522314370412\n",
      "step : 300/2140, loss : 1.0060097107067494\n",
      "step : 450/2140, loss : 1.0145581267543688\n",
      "step : 600/2140, loss : 1.0408959832733444\n",
      "step : 750/2140, loss : 1.017476630769744\n",
      "step : 900/2140, loss : 1.023561547258315\n",
      "step : 1050/2140, loss : 1.0324939062694936\n",
      "step : 1200/2140, loss : 1.0258748510518385\n",
      "step : 1350/2140, loss : 1.0203460711667414\n",
      "step : 1500/2140, loss : 1.0132782720911546\n",
      "step : 1650/2140, loss : 1.022335571819906\n",
      "step : 1800/2140, loss : 1.010618594994478\n",
      "step : 1950/2140, loss : 1.0075586048812029\n",
      "step : 2100/2140, loss : 1.0198471867299768\n",
      "epoch = 10 loss = 0.5904896855354309 validation multi-class accuracy = 0.8817\n",
      "step : 0/2140, loss : 1.0832538604736328\n",
      "step : 150/2140, loss : 1.032408041497824\n",
      "step : 300/2140, loss : 1.0162583973298331\n",
      "step : 450/2140, loss : 1.0067969752866262\n",
      "step : 600/2140, loss : 1.0089415797927475\n",
      "step : 750/2140, loss : 1.0049801600670811\n",
      "step : 900/2140, loss : 1.0085706406804331\n",
      "step : 1050/2140, loss : 1.0180974681441552\n",
      "step : 1200/2140, loss : 1.0278935526606485\n",
      "step : 1350/2140, loss : 1.0276528243466696\n",
      "step : 1500/2140, loss : 1.0145066857592342\n",
      "step : 1650/2140, loss : 1.0250594925255294\n",
      "step : 1800/2140, loss : 1.0144277767660919\n",
      "step : 1950/2140, loss : 0.9970902345750452\n",
      "step : 2100/2140, loss : 1.0015891629985705\n",
      "epoch = 11 loss = 0.6828028559684753 validation multi-class accuracy = 0.8916\n",
      "epoch = 11 loss = 0.7186223864555359 validation multi-class accuracy = 0.9011\n",
      "Training with 1 started\n",
      "17115 4279\n",
      "step : 0/2140, loss : 1.7371138334274292\n",
      "step : 150/2140, loss : 1.3523253966694837\n",
      "step : 300/2140, loss : 1.2172427750629249\n",
      "step : 450/2140, loss : 1.13960835948033\n",
      "step : 600/2140, loss : 1.1012625566447387\n",
      "step : 750/2140, loss : 1.0891994134004752\n",
      "step : 900/2140, loss : 1.1022547798142504\n",
      "step : 1050/2140, loss : 1.0953886547371203\n",
      "step : 1200/2140, loss : 1.0790442004367076\n",
      "step : 1350/2140, loss : 1.0801468600262036\n",
      "step : 1500/2140, loss : 1.0752169379168641\n",
      "step : 1650/2140, loss : 1.1002604228363415\n",
      "step : 1800/2140, loss : 1.0903485955152987\n",
      "step : 1950/2140, loss : 1.0678841442750764\n",
      "step : 2100/2140, loss : 1.0711014125362308\n",
      "epoch = 1 loss = 0.4765794277191162 validation multi-class accuracy = 0.8474\n",
      "step : 0/2140, loss : 1.0694820880889893\n",
      "step : 150/2140, loss : 1.0678097149939327\n",
      "step : 300/2140, loss : 1.0685581044478907\n",
      "step : 450/2140, loss : 1.0679927443717059\n",
      "step : 600/2140, loss : 1.047349707265031\n",
      "step : 750/2140, loss : 1.060553368748335\n",
      "step : 900/2140, loss : 1.0552783053337826\n",
      "step : 1050/2140, loss : 1.0668077294460083\n",
      "step : 1200/2140, loss : 1.0548913018975052\n",
      "step : 1350/2140, loss : 1.060190223549548\n",
      "step : 1500/2140, loss : 1.066109120767507\n",
      "step : 1650/2140, loss : 1.0598430387258213\n",
      "step : 1800/2140, loss : 1.0615509816191904\n",
      "step : 1950/2140, loss : 1.056408790285884\n",
      "step : 2100/2140, loss : 1.0677246176155515\n",
      "epoch = 2 loss = 0.33253243565559387 validation multi-class accuracy = 0.8626\n",
      "step : 0/2140, loss : 1.007520079612732\n",
      "step : 150/2140, loss : 1.0415367080664115\n",
      "step : 300/2140, loss : 1.0483859578623844\n",
      "step : 450/2140, loss : 1.043924189604166\n",
      "step : 600/2140, loss : 1.0535346070877403\n",
      "step : 750/2140, loss : 1.0438692468897162\n",
      "step : 900/2140, loss : 1.0519057595665633\n",
      "step : 1050/2140, loss : 1.054967671581124\n",
      "step : 1200/2140, loss : 1.0518507020089838\n",
      "step : 1350/2140, loss : 1.0575615297436898\n",
      "step : 1500/2140, loss : 1.057375028555084\n",
      "step : 1650/2140, loss : 1.0541755817754939\n",
      "step : 1800/2140, loss : 1.0490614720486324\n",
      "step : 1950/2140, loss : 1.05608457480414\n",
      "step : 2100/2140, loss : 1.0543255792031163\n",
      "epoch = 3 loss = 0.39570388197898865 validation multi-class accuracy = 0.8553\n",
      "step : 0/2140, loss : 0.9326537251472473\n",
      "step : 150/2140, loss : 1.0309956742493271\n",
      "step : 300/2140, loss : 1.0514475939419712\n",
      "step : 450/2140, loss : 1.038752893641326\n",
      "step : 600/2140, loss : 1.049617209343277\n",
      "step : 750/2140, loss : 1.0621409162699051\n",
      "step : 900/2140, loss : 1.0496878582444744\n",
      "step : 1050/2140, loss : 1.0311471580830907\n",
      "step : 1200/2140, loss : 1.0286607706923145\n",
      "step : 1350/2140, loss : 1.0441390362248886\n",
      "step : 1500/2140, loss : 1.0448594207855342\n",
      "step : 1650/2140, loss : 1.044326410603505\n",
      "step : 1800/2140, loss : 1.0380473049332948\n",
      "step : 1950/2140, loss : 1.0396658128210166\n",
      "step : 2100/2140, loss : 1.0354483030184094\n",
      "epoch = 4 loss = 0.4053169786930084 validation multi-class accuracy = 0.8666\n",
      "step : 0/2140, loss : 1.01140558719635\n",
      "step : 150/2140, loss : 1.0185810178970536\n",
      "step : 300/2140, loss : 1.0208647624515421\n",
      "step : 450/2140, loss : 1.0397317401731336\n",
      "step : 600/2140, loss : 1.0479466862711577\n",
      "step : 750/2140, loss : 1.043815025601116\n",
      "step : 900/2140, loss : 1.0314084683448577\n",
      "step : 1050/2140, loss : 1.0494117522124708\n",
      "step : 1200/2140, loss : 1.0430769136796982\n",
      "step : 1350/2140, loss : 1.038230882709787\n",
      "step : 1500/2140, loss : 1.0467220243541393\n",
      "step : 1650/2140, loss : 1.03973836765518\n",
      "step : 1800/2140, loss : 1.0349796206530766\n",
      "step : 1950/2140, loss : 1.0386283291633551\n",
      "step : 2100/2140, loss : 1.0441991126187966\n",
      "epoch = 5 loss = 0.4719918668270111 validation multi-class accuracy = 0.8698\n",
      "step : 0/2140, loss : 0.9329402446746826\n",
      "step : 150/2140, loss : 1.0051931145218345\n",
      "step : 300/2140, loss : 1.021232266971258\n",
      "step : 450/2140, loss : 1.0362248886423029\n",
      "step : 600/2140, loss : 1.0395477035565752\n",
      "step : 750/2140, loss : 1.0403499187576057\n",
      "step : 900/2140, loss : 1.0432699557286351\n",
      "step : 1050/2140, loss : 1.0507328443859925\n",
      "step : 1200/2140, loss : 1.0352431645466598\n",
      "step : 1350/2140, loss : 1.0438579303137299\n",
      "step : 1500/2140, loss : 1.0180621264011032\n",
      "step : 1650/2140, loss : 1.031165886023737\n",
      "step : 1800/2140, loss : 1.0198438399689502\n",
      "step : 1950/2140, loss : 1.04421369840827\n",
      "step : 2100/2140, loss : 1.0343843719304098\n",
      "epoch = 6 loss = 0.4184456765651703 validation multi-class accuracy = 0.8598\n",
      "step : 0/2140, loss : 1.0645825862884521\n",
      "step : 150/2140, loss : 1.0335502146095614\n",
      "step : 300/2140, loss : 1.0255541618942619\n",
      "step : 450/2140, loss : 1.0138560584578757\n",
      "step : 600/2140, loss : 1.0361936682477442\n",
      "step : 750/2140, loss : 1.0208891205540283\n",
      "step : 900/2140, loss : 1.0237533494483455\n",
      "step : 1050/2140, loss : 1.0419943300232155\n",
      "step : 1200/2140, loss : 1.0374246851790456\n",
      "step : 1350/2140, loss : 1.04052747900251\n",
      "step : 1500/2140, loss : 1.0371645289374856\n",
      "step : 1650/2140, loss : 1.0358413440089196\n",
      "step : 1800/2140, loss : 1.0399604917609542\n",
      "step : 1950/2140, loss : 1.0361493547856238\n",
      "step : 2100/2140, loss : 1.0198202199934125\n",
      "epoch = 7 loss = 0.41785839200019836 validation multi-class accuracy = 0.8642\n",
      "step : 0/2140, loss : 0.9349119067192078\n",
      "step : 150/2140, loss : 0.9905435788078139\n",
      "step : 300/2140, loss : 1.0105705308376136\n",
      "step : 450/2140, loss : 1.0318607424811737\n",
      "step : 600/2140, loss : 1.0233331668503225\n",
      "step : 750/2140, loss : 1.0425126987615732\n",
      "step : 900/2140, loss : 1.0131281490107515\n",
      "step : 1050/2140, loss : 1.0089998469512031\n",
      "step : 1200/2140, loss : 1.0231534297165132\n",
      "step : 1350/2140, loss : 1.0254654878116176\n",
      "step : 1500/2140, loss : 1.0437994021486243\n",
      "step : 1650/2140, loss : 1.0253385460446323\n",
      "step : 1800/2140, loss : 1.0300215109672364\n",
      "step : 1950/2140, loss : 1.0276274857855239\n",
      "step : 2100/2140, loss : 1.0249302362899968\n",
      "epoch = 8 loss = 0.3683413863182068 validation multi-class accuracy = 0.8754\n",
      "step : 0/2140, loss : 0.9369655847549438\n",
      "step : 150/2140, loss : 0.9904129900399917\n",
      "step : 300/2140, loss : 1.019799244012116\n",
      "step : 450/2140, loss : 1.0189476821786627\n",
      "step : 600/2140, loss : 1.017839612860137\n",
      "step : 750/2140, loss : 1.0098136084511298\n",
      "step : 900/2140, loss : 1.0140852661495898\n",
      "step : 1050/2140, loss : 1.0195114253634576\n",
      "step : 1200/2140, loss : 1.016244954290937\n",
      "step : 1350/2140, loss : 1.0141344941797257\n",
      "step : 1500/2140, loss : 1.0228034123453575\n",
      "step : 1650/2140, loss : 1.0110646029259909\n",
      "step : 1800/2140, loss : 1.0098992903981208\n",
      "step : 1950/2140, loss : 1.0233089149137602\n",
      "step : 2100/2140, loss : 1.0291256589364122\n",
      "epoch = 9 loss = 0.5427435636520386 validation multi-class accuracy = 0.8754\n",
      "step : 0/2140, loss : 1.1145687103271484\n",
      "step : 150/2140, loss : 1.024664119442781\n",
      "step : 300/2140, loss : 1.0138341524336376\n",
      "step : 450/2140, loss : 1.0141966785129273\n",
      "step : 600/2140, loss : 1.0205037054480994\n",
      "step : 750/2140, loss : 1.0122675298745099\n",
      "step : 900/2140, loss : 1.0013556791938325\n",
      "step : 1050/2140, loss : 1.0136600087900889\n",
      "step : 1200/2140, loss : 1.0306384639987811\n",
      "step : 1350/2140, loss : 1.0234437052662295\n",
      "step : 1500/2140, loss : 1.0144531078192534\n",
      "step : 1650/2140, loss : 1.0216634627559562\n",
      "step : 1800/2140, loss : 1.0021876471577158\n",
      "step : 1950/2140, loss : 1.0197522420284353\n",
      "step : 2100/2140, loss : 1.0183083326095137\n",
      "epoch = 10 loss = 0.43398380279541016 validation multi-class accuracy = 0.8712\n",
      "step : 0/2140, loss : 1.1954818964004517\n",
      "step : 150/2140, loss : 1.0521172080440082\n",
      "step : 300/2140, loss : 1.0365972933246237\n",
      "step : 450/2140, loss : 1.002123900168723\n",
      "step : 600/2140, loss : 1.0010821360623563\n",
      "step : 750/2140, loss : 1.017887207920725\n",
      "step : 900/2140, loss : 1.0174898473454905\n",
      "step : 1050/2140, loss : 0.9961125194451397\n",
      "step : 1200/2140, loss : 1.0074813318097229\n",
      "step : 1350/2140, loss : 1.0101700822815567\n",
      "step : 1500/2140, loss : 1.0292584871970882\n",
      "step : 1650/2140, loss : 1.024536942044388\n",
      "step : 1800/2140, loss : 1.0070024997677198\n",
      "step : 1950/2140, loss : 1.0108766717612554\n",
      "step : 2100/2140, loss : 1.0001881422382248\n",
      "epoch = 11 loss = 0.5766557455062866 validation multi-class accuracy = 0.8696\n",
      "epoch = 11 loss = 0.34847283363342285 validation multi-class accuracy = 0.8855\n",
      "Training with 2 started\n",
      "17115 4279\n",
      "step : 0/2140, loss : 1.531378149986267\n",
      "step : 150/2140, loss : 1.3015506305720015\n",
      "step : 300/2140, loss : 1.1864980702397392\n",
      "step : 450/2140, loss : 1.1402629798875095\n",
      "step : 600/2140, loss : 1.1245235409952474\n",
      "step : 750/2140, loss : 1.089122791672428\n",
      "step : 900/2140, loss : 1.0804713409250686\n",
      "step : 1050/2140, loss : 1.100351628028534\n",
      "step : 1200/2140, loss : 1.0861028520820772\n",
      "step : 1350/2140, loss : 1.0819744258428903\n",
      "step : 1500/2140, loss : 1.0626109281315093\n",
      "step : 1650/2140, loss : 1.078116537054799\n",
      "step : 1800/2140, loss : 1.0791142224786427\n",
      "step : 1950/2140, loss : 1.0761582974842183\n",
      "step : 2100/2140, loss : 1.0723979311899716\n",
      "epoch = 1 loss = 0.3166435658931732 validation multi-class accuracy = 0.8598\n",
      "step : 0/2140, loss : 1.037996530532837\n",
      "step : 150/2140, loss : 1.066622875230409\n",
      "step : 300/2140, loss : 1.0650672299522437\n",
      "step : 450/2140, loss : 1.060669040608105\n",
      "step : 600/2140, loss : 1.0668775988524288\n",
      "step : 750/2140, loss : 1.0581300908219613\n",
      "step : 900/2140, loss : 1.044044324666412\n",
      "step : 1050/2140, loss : 1.0525027468838952\n",
      "step : 1200/2140, loss : 1.077550045518231\n",
      "step : 1350/2140, loss : 1.0745433767704775\n",
      "step : 1500/2140, loss : 1.0528197858065078\n",
      "step : 1650/2140, loss : 1.0515133926528404\n",
      "step : 1800/2140, loss : 1.0715801272150747\n",
      "step : 1950/2140, loss : 1.0582916270110816\n",
      "step : 2100/2140, loss : 1.0607036187898486\n",
      "epoch = 2 loss = 0.4232538640499115 validation multi-class accuracy = 0.8413\n",
      "step : 0/2140, loss : 1.1027263402938843\n",
      "step : 150/2140, loss : 1.0616519082175038\n",
      "step : 300/2140, loss : 1.0550508222451644\n",
      "step : 450/2140, loss : 1.0415891074445425\n",
      "step : 600/2140, loss : 1.0559034541202497\n",
      "step : 750/2140, loss : 1.0568931896942118\n",
      "step : 900/2140, loss : 1.04863574661209\n",
      "step : 1050/2140, loss : 1.055153564835138\n",
      "step : 1200/2140, loss : 1.0489392937462854\n",
      "step : 1350/2140, loss : 1.0436342878366216\n",
      "step : 1500/2140, loss : 1.045327001707495\n",
      "step : 1650/2140, loss : 1.041694495237342\n",
      "step : 1800/2140, loss : 1.0573244989373916\n",
      "step : 1950/2140, loss : 1.054092124038847\n",
      "step : 2100/2140, loss : 1.0704705916488297\n",
      "epoch = 3 loss = 0.41618087887763977 validation multi-class accuracy = 0.8614\n",
      "step : 0/2140, loss : 1.0223846435546875\n",
      "step : 150/2140, loss : 1.054092400142903\n",
      "step : 300/2140, loss : 1.043034396102157\n",
      "step : 450/2140, loss : 1.0278397978782916\n",
      "step : 600/2140, loss : 1.0437783751451934\n",
      "step : 750/2140, loss : 1.0524669325141938\n",
      "step : 900/2140, loss : 1.0511884154396134\n",
      "step : 1050/2140, loss : 1.0533194498833711\n",
      "step : 1200/2140, loss : 1.0336969140643453\n",
      "step : 1350/2140, loss : 1.04662358014838\n",
      "step : 1500/2140, loss : 1.0443631873383423\n",
      "step : 1650/2140, loss : 1.0363505830019044\n",
      "step : 1800/2140, loss : 1.0358311232068658\n",
      "step : 1950/2140, loss : 1.0370460181893806\n",
      "step : 2100/2140, loss : 1.048566239027659\n",
      "epoch = 4 loss = 0.3523731827735901 validation multi-class accuracy = 0.8633\n",
      "step : 0/2140, loss : 0.8928375244140625\n",
      "step : 150/2140, loss : 1.0136098366511788\n",
      "step : 300/2140, loss : 1.025452569788545\n",
      "step : 450/2140, loss : 1.051148986808586\n",
      "step : 600/2140, loss : 1.0445531884384538\n",
      "step : 750/2140, loss : 1.037393104044054\n",
      "step : 900/2140, loss : 1.0376338033936527\n",
      "step : 1050/2140, loss : 1.0223622414280342\n",
      "step : 1200/2140, loss : 1.0421565852887895\n",
      "step : 1350/2140, loss : 1.0452703557634129\n",
      "step : 1500/2140, loss : 1.0630410810969437\n",
      "step : 1650/2140, loss : 1.0519874266857179\n",
      "step : 1800/2140, loss : 1.0394952411418907\n",
      "step : 1950/2140, loss : 1.038262576992543\n",
      "step : 2100/2140, loss : 1.035915471658288\n",
      "epoch = 5 loss = 0.3136194050312042 validation multi-class accuracy = 0.8673\n",
      "step : 0/2140, loss : 1.1322020292282104\n",
      "step : 150/2140, loss : 1.0643166049338408\n",
      "step : 300/2140, loss : 1.0406863900137358\n",
      "step : 450/2140, loss : 1.0231108184631716\n",
      "step : 600/2140, loss : 1.0451464756272746\n",
      "step : 750/2140, loss : 1.0351069993630815\n",
      "step : 900/2140, loss : 1.027841470276691\n",
      "step : 1050/2140, loss : 1.0219258177187038\n",
      "step : 1200/2140, loss : 1.034065457115124\n",
      "step : 1350/2140, loss : 1.026786359202202\n",
      "step : 1500/2140, loss : 1.0301558681741523\n",
      "step : 1650/2140, loss : 1.0276591091371492\n",
      "step : 1800/2140, loss : 1.0423640653118846\n",
      "step : 1950/2140, loss : 1.043174763291013\n",
      "step : 2100/2140, loss : 1.028980978899423\n",
      "epoch = 6 loss = 0.3312937915325165 validation multi-class accuracy = 0.8624\n",
      "step : 0/2140, loss : 1.0687692165374756\n",
      "step : 150/2140, loss : 1.0327431513795753\n",
      "step : 300/2140, loss : 1.0194020982011167\n",
      "step : 450/2140, loss : 1.023685642894759\n",
      "step : 600/2140, loss : 1.0277912478543518\n",
      "step : 750/2140, loss : 1.0218011434137262\n",
      "step : 900/2140, loss : 1.0039698599424696\n",
      "step : 1050/2140, loss : 1.021148621980518\n",
      "step : 1200/2140, loss : 1.0147548194315221\n",
      "step : 1350/2140, loss : 1.0358991798468282\n",
      "step : 1500/2140, loss : 1.033472070993107\n",
      "step : 1650/2140, loss : 1.0244472089034635\n",
      "step : 1800/2140, loss : 1.0417366001728747\n",
      "step : 1950/2140, loss : 1.034810972930905\n",
      "step : 2100/2140, loss : 1.0335527063404928\n",
      "epoch = 7 loss = 0.38501325249671936 validation multi-class accuracy = 0.8570\n",
      "step : 0/2140, loss : 0.9797036051750183\n",
      "step : 150/2140, loss : 1.0147083302121955\n",
      "step : 300/2140, loss : 1.0159775460537375\n",
      "step : 450/2140, loss : 1.0348203327765766\n",
      "step : 600/2140, loss : 1.0307753473124013\n",
      "step : 750/2140, loss : 1.0195672732963388\n",
      "step : 900/2140, loss : 1.0155896169892373\n",
      "step : 1050/2140, loss : 1.0204140533761865\n",
      "step : 1200/2140, loss : 1.0191130579244418\n",
      "step : 1350/2140, loss : 1.0160407072441904\n",
      "step : 1500/2140, loss : 1.0336668696921232\n",
      "step : 1650/2140, loss : 1.050702341193884\n",
      "step : 1800/2140, loss : 1.0346774069887263\n",
      "step : 1950/2140, loss : 1.037375369556829\n",
      "step : 2100/2140, loss : 1.0295416256943155\n",
      "epoch = 8 loss = 0.42235130071640015 validation multi-class accuracy = 0.8546\n",
      "step : 0/2140, loss : 0.938571572303772\n",
      "step : 150/2140, loss : 0.9977316757728388\n",
      "step : 300/2140, loss : 1.002534353321872\n",
      "step : 450/2140, loss : 1.0164847578720366\n",
      "step : 600/2140, loss : 1.0234276276241219\n",
      "step : 750/2140, loss : 1.0015040034059806\n",
      "step : 900/2140, loss : 1.0123819364040703\n",
      "step : 1050/2140, loss : 1.013789531021426\n",
      "step : 1200/2140, loss : 1.014996850305739\n",
      "step : 1350/2140, loss : 1.0180967738745221\n",
      "step : 1500/2140, loss : 1.0222720987733216\n",
      "step : 1650/2140, loss : 1.031188187597922\n",
      "step : 1800/2140, loss : 1.0265687771240404\n",
      "step : 1950/2140, loss : 1.0396531671063185\n",
      "step : 2100/2140, loss : 1.0282056188017048\n",
      "epoch = 9 loss = 0.30320289731025696 validation multi-class accuracy = 0.8558\n",
      "step : 0/2140, loss : 0.9411369562149048\n",
      "step : 150/2140, loss : 1.000571526586194\n",
      "step : 300/2140, loss : 0.9934885447582217\n",
      "step : 450/2140, loss : 1.0122465950935264\n",
      "step : 600/2140, loss : 1.0054552120989633\n",
      "step : 750/2140, loss : 1.0106845643732234\n",
      "step : 900/2140, loss : 1.0252236495997096\n",
      "step : 1050/2140, loss : 1.0139888005838213\n",
      "step : 1200/2140, loss : 1.0213700529453074\n",
      "step : 1350/2140, loss : 1.0149646733751243\n",
      "step : 1500/2140, loss : 1.0177380754997305\n",
      "step : 1650/2140, loss : 1.0126928126345978\n",
      "step : 1800/2140, loss : 1.0164457976371282\n",
      "step : 1950/2140, loss : 1.0196481076997104\n",
      "step : 2100/2140, loss : 1.0087565739755353\n",
      "epoch = 10 loss = 0.29547303915023804 validation multi-class accuracy = 0.8663\n",
      "step : 0/2140, loss : 1.0540416240692139\n",
      "step : 150/2140, loss : 1.01207077660441\n",
      "step : 300/2140, loss : 1.010142771861488\n",
      "step : 450/2140, loss : 1.0071601122105878\n",
      "step : 600/2140, loss : 1.0120673157667397\n",
      "step : 750/2140, loss : 1.0160075613109771\n",
      "step : 900/2140, loss : 0.9991158325371033\n",
      "step : 1050/2140, loss : 1.0163132189761195\n",
      "step : 1200/2140, loss : 1.0197387115133572\n",
      "step : 1350/2140, loss : 1.0019149380370465\n",
      "step : 1500/2140, loss : 1.0069149829881838\n",
      "step : 1650/2140, loss : 1.0057183186091423\n",
      "step : 1800/2140, loss : 1.0250808887802882\n",
      "step : 1950/2140, loss : 1.013028579828744\n",
      "step : 2100/2140, loss : 1.0136706204599781\n",
      "epoch = 11 loss = 0.2830033004283905 validation multi-class accuracy = 0.8780\n",
      "epoch = 11 loss = 0.2839265465736389 validation multi-class accuracy = 0.8906\n",
      "Training with 3 started\n",
      "17115 4279\n",
      "step : 0/2140, loss : 1.5758116245269775\n",
      "step : 150/2140, loss : 1.2902637086576796\n",
      "step : 300/2140, loss : 1.1784656892661691\n",
      "step : 450/2140, loss : 1.1469011393647828\n",
      "step : 600/2140, loss : 1.1141499501815735\n",
      "step : 750/2140, loss : 1.094066080928631\n",
      "step : 900/2140, loss : 1.1147360360364258\n",
      "step : 1050/2140, loss : 1.0750367811697354\n",
      "step : 1200/2140, loss : 1.081566075486867\n",
      "step : 1350/2140, loss : 1.075268504004091\n",
      "step : 1500/2140, loss : 1.067475018887658\n",
      "step : 1650/2140, loss : 1.087596642939449\n",
      "step : 1800/2140, loss : 1.0813449722093458\n",
      "step : 1950/2140, loss : 1.0830374614606917\n",
      "step : 2100/2140, loss : 1.0702985179033806\n",
      "epoch = 1 loss = 0.7524482607841492 validation multi-class accuracy = 0.8406\n",
      "step : 0/2140, loss : 1.3990039825439453\n",
      "step : 150/2140, loss : 1.1300058316310075\n",
      "step : 300/2140, loss : 1.0641140468479775\n",
      "step : 450/2140, loss : 1.0951311163304447\n",
      "step : 600/2140, loss : 1.0746059565509603\n",
      "step : 750/2140, loss : 1.0719340386486553\n",
      "step : 900/2140, loss : 1.0622957959381272\n",
      "step : 1050/2140, loss : 1.0723815575637339\n",
      "step : 1200/2140, loss : 1.062887315198362\n",
      "step : 1350/2140, loss : 1.0687284054796007\n",
      "step : 1500/2140, loss : 1.0675789238923805\n",
      "step : 1650/2140, loss : 1.0516693167720976\n",
      "step : 1800/2140, loss : 1.0562963549016673\n",
      "step : 1950/2140, loss : 1.0443872359904298\n",
      "step : 2100/2140, loss : 1.061066032509104\n",
      "epoch = 2 loss = 0.7878546118736267 validation multi-class accuracy = 0.8696\n",
      "step : 0/2140, loss : 0.9113149642944336\n",
      "step : 150/2140, loss : 1.0280296450764166\n",
      "step : 300/2140, loss : 1.0279524548689813\n",
      "step : 450/2140, loss : 1.0501291530774477\n",
      "step : 600/2140, loss : 1.0393354350225619\n",
      "step : 750/2140, loss : 1.0568902071679527\n",
      "step : 900/2140, loss : 1.0590554556952925\n",
      "step : 1050/2140, loss : 1.062528518111664\n",
      "step : 1200/2140, loss : 1.047407118077677\n",
      "step : 1350/2140, loss : 1.0470463999504427\n",
      "step : 1500/2140, loss : 1.0620645918044906\n",
      "step : 1650/2140, loss : 1.0721114314463385\n",
      "step : 1800/2140, loss : 1.0658319728343608\n",
      "step : 1950/2140, loss : 1.0493978319376704\n",
      "step : 2100/2140, loss : 1.066550883421669\n",
      "epoch = 3 loss = 0.6097889542579651 validation multi-class accuracy = 0.8780\n",
      "step : 0/2140, loss : 1.0021638870239258\n",
      "step : 150/2140, loss : 1.006119023855727\n",
      "step : 300/2140, loss : 1.0439803073152338\n",
      "step : 450/2140, loss : 1.0538108219399263\n",
      "step : 600/2140, loss : 1.054726030045818\n",
      "step : 750/2140, loss : 1.0448282144460663\n",
      "step : 900/2140, loss : 1.0512425848389293\n",
      "step : 1050/2140, loss : 1.0460529637023865\n",
      "step : 1200/2140, loss : 1.053095297909297\n",
      "step : 1350/2140, loss : 1.041100560555611\n",
      "step : 1500/2140, loss : 1.0558879528977416\n",
      "step : 1650/2140, loss : 1.054330179676529\n",
      "step : 1800/2140, loss : 1.0559891143878681\n",
      "step : 1950/2140, loss : 1.0533115359753784\n",
      "step : 2100/2140, loss : 1.0383600039802772\n",
      "epoch = 4 loss = 0.5920585989952087 validation multi-class accuracy = 0.8712\n",
      "step : 0/2140, loss : 1.2098727226257324\n",
      "step : 150/2140, loss : 1.082690090011609\n",
      "step : 300/2140, loss : 1.0504756142755982\n",
      "step : 450/2140, loss : 1.0402256209632248\n",
      "step : 600/2140, loss : 1.0405673209593647\n",
      "step : 750/2140, loss : 1.0449671845153796\n",
      "step : 900/2140, loss : 1.0327513871783294\n",
      "step : 1050/2140, loss : 1.0474766426300666\n",
      "step : 1200/2140, loss : 1.0320154008291098\n",
      "step : 1350/2140, loss : 1.047415618794946\n",
      "step : 1500/2140, loss : 1.0529133952241778\n",
      "step : 1650/2140, loss : 1.053685520422495\n",
      "step : 1800/2140, loss : 1.047934312815462\n",
      "step : 1950/2140, loss : 1.0386279602659265\n",
      "step : 2100/2140, loss : 1.036402267483231\n",
      "epoch = 5 loss = 0.3561353087425232 validation multi-class accuracy = 0.8724\n",
      "step : 0/2140, loss : 0.9977191090583801\n",
      "step : 150/2140, loss : 1.0217143316990775\n",
      "step : 300/2140, loss : 1.027982180523855\n",
      "step : 450/2140, loss : 1.041447886046751\n",
      "step : 600/2140, loss : 1.0382675524795189\n",
      "step : 750/2140, loss : 1.024990494608664\n",
      "step : 900/2140, loss : 1.04352782728488\n",
      "step : 1050/2140, loss : 1.0372219355103716\n",
      "step : 1200/2140, loss : 1.0509120484511592\n",
      "step : 1350/2140, loss : 1.0337434193869788\n",
      "step : 1500/2140, loss : 1.0253557853261381\n",
      "step : 1650/2140, loss : 1.0373265508616103\n",
      "step : 1800/2140, loss : 1.0488557506815317\n",
      "step : 1950/2140, loss : 1.049155929564658\n",
      "step : 2100/2140, loss : 1.045628581816319\n",
      "epoch = 6 loss = 0.5793060660362244 validation multi-class accuracy = 0.8722\n",
      "step : 0/2140, loss : 1.1131954193115234\n",
      "step : 150/2140, loss : 1.046631593320769\n",
      "step : 300/2140, loss : 1.030652100246646\n",
      "step : 450/2140, loss : 1.0184602832899186\n",
      "step : 600/2140, loss : 1.032903357358682\n",
      "step : 750/2140, loss : 1.0311890937888044\n",
      "step : 900/2140, loss : 1.0193969134937775\n",
      "step : 1050/2140, loss : 1.0294246341724371\n",
      "step : 1200/2140, loss : 1.0281951127303957\n",
      "step : 1350/2140, loss : 1.0261655501776377\n",
      "step : 1500/2140, loss : 1.0315044287799304\n",
      "step : 1650/2140, loss : 1.0185753314712875\n",
      "step : 1800/2140, loss : 1.039080709645927\n",
      "step : 1950/2140, loss : 1.037290962996844\n",
      "step : 2100/2140, loss : 1.0364275274668355\n",
      "epoch = 7 loss = 0.8764929175376892 validation multi-class accuracy = 0.8577\n",
      "step : 0/2140, loss : 1.0936368703842163\n",
      "step : 150/2140, loss : 1.043136886166958\n",
      "step : 300/2140, loss : 1.0243051060648753\n",
      "step : 450/2140, loss : 1.0292675094893133\n",
      "step : 600/2140, loss : 1.0160497953551184\n",
      "step : 750/2140, loss : 1.0235468195493003\n",
      "step : 900/2140, loss : 1.0259305317575673\n",
      "step : 1050/2140, loss : 1.0229293044231225\n",
      "step : 1200/2140, loss : 1.0276823414627194\n",
      "step : 1350/2140, loss : 1.0343763587177968\n",
      "step : 1500/2140, loss : 1.0247074176265933\n",
      "step : 1650/2140, loss : 1.021606272693471\n",
      "step : 1800/2140, loss : 1.0085034077807802\n",
      "step : 1950/2140, loss : 1.0304626290862808\n",
      "step : 2100/2140, loss : 1.0288659750853257\n",
      "epoch = 8 loss = 0.41243332624435425 validation multi-class accuracy = 0.8729\n",
      "step : 0/2140, loss : 0.9172881841659546\n",
      "step : 150/2140, loss : 1.0014312845808782\n",
      "step : 300/2140, loss : 1.0168480220822775\n",
      "step : 450/2140, loss : 1.034492804979693\n",
      "step : 600/2140, loss : 1.0108255525048957\n",
      "step : 750/2140, loss : 1.0331376930420644\n",
      "step : 900/2140, loss : 1.0253971790666607\n",
      "step : 1050/2140, loss : 1.008585475260766\n",
      "step : 1200/2140, loss : 1.015528583312195\n",
      "step : 1350/2140, loss : 1.0143913583943267\n",
      "step : 1500/2140, loss : 1.0037660522145906\n",
      "step : 1650/2140, loss : 1.0366488850104154\n",
      "step : 1800/2140, loss : 1.0282148491279297\n",
      "step : 1950/2140, loss : 1.038349099350908\n",
      "step : 2100/2140, loss : 1.0145529050280266\n",
      "epoch = 9 loss = 0.43992725014686584 validation multi-class accuracy = 0.8710\n",
      "step : 0/2140, loss : 0.9678331017494202\n",
      "step : 150/2140, loss : 1.0008449782961935\n",
      "step : 300/2140, loss : 1.0116818191080352\n",
      "step : 450/2140, loss : 0.9990752579729207\n",
      "step : 600/2140, loss : 1.019806332664266\n",
      "step : 750/2140, loss : 1.0206679533837562\n",
      "step : 900/2140, loss : 1.0118723632012503\n",
      "step : 1050/2140, loss : 1.005810975394351\n",
      "step : 1200/2140, loss : 1.0120465971793156\n",
      "step : 1350/2140, loss : 1.014163362956378\n",
      "step : 1500/2140, loss : 1.0244506784783174\n",
      "step : 1650/2140, loss : 1.0233081664621682\n",
      "step : 1800/2140, loss : 1.0221614411080473\n",
      "step : 1950/2140, loss : 1.0155884112458504\n",
      "step : 2100/2140, loss : 1.025884269382192\n",
      "epoch = 10 loss = 0.48611965775489807 validation multi-class accuracy = 0.8747\n",
      "step : 0/2140, loss : 0.9723652601242065\n",
      "step : 150/2140, loss : 0.9943718481885904\n",
      "step : 300/2140, loss : 1.0099355841581363\n",
      "step : 450/2140, loss : 1.0197460160160314\n",
      "step : 600/2140, loss : 0.9976132724490182\n",
      "step : 750/2140, loss : 0.9966475759967437\n",
      "step : 900/2140, loss : 1.0183360914585144\n",
      "step : 1050/2140, loss : 1.0141871340046065\n",
      "step : 1200/2140, loss : 1.0117176715259288\n",
      "step : 1350/2140, loss : 1.0157302003510358\n",
      "step : 1500/2140, loss : 1.0132948297199529\n",
      "step : 1650/2140, loss : 1.0246550395059846\n",
      "step : 1800/2140, loss : 1.023242998004528\n",
      "step : 1950/2140, loss : 1.02152529664146\n",
      "step : 2100/2140, loss : 1.020251631526914\n",
      "epoch = 11 loss = 0.4484725892543793 validation multi-class accuracy = 0.8687\n",
      "epoch = 11 loss = 0.4438501000404358 validation multi-class accuracy = 0.8864\n",
      "Training with 4 started\n",
      "17116 4278\n",
      "step : 0/2140, loss : 1.7083913087844849\n",
      "step : 150/2140, loss : 1.3047380488668523\n",
      "step : 300/2140, loss : 1.1750255937748233\n",
      "step : 450/2140, loss : 1.1190209590788327\n",
      "step : 600/2140, loss : 1.101153963518028\n",
      "step : 750/2140, loss : 1.095575535318991\n",
      "step : 900/2140, loss : 1.1054195039055679\n",
      "step : 1050/2140, loss : 1.0947520729214724\n",
      "step : 1200/2140, loss : 1.0909471561824087\n",
      "step : 1350/2140, loss : 1.0994333521283997\n",
      "step : 1500/2140, loss : 1.079742112714811\n",
      "step : 1650/2140, loss : 1.0760924870231978\n",
      "step : 1800/2140, loss : 1.089643288265064\n",
      "step : 1950/2140, loss : 1.0693234129245903\n",
      "step : 2100/2140, loss : 1.0710946451508319\n",
      "epoch = 1 loss = 0.9645616412162781 validation multi-class accuracy = 0.8504\n",
      "step : 0/2140, loss : 0.9952279925346375\n",
      "step : 150/2140, loss : 1.0527889602793217\n",
      "step : 300/2140, loss : 1.058843561373152\n",
      "step : 450/2140, loss : 1.0572995321357543\n",
      "step : 600/2140, loss : 1.0591042214373654\n",
      "step : 750/2140, loss : 1.0778905770751341\n",
      "step : 900/2140, loss : 1.0691459346089172\n",
      "step : 1050/2140, loss : 1.058167445921687\n",
      "step : 1200/2140, loss : 1.0676612958396234\n",
      "step : 1350/2140, loss : 1.0775384831400059\n",
      "step : 1500/2140, loss : 1.0653383876255405\n",
      "step : 1650/2140, loss : 1.0626648457242278\n",
      "step : 1800/2140, loss : 1.049862915884003\n",
      "step : 1950/2140, loss : 1.0641495639008862\n",
      "step : 2100/2140, loss : 1.0577935489705417\n",
      "epoch = 2 loss = 0.8439376950263977 validation multi-class accuracy = 0.8787\n",
      "step : 0/2140, loss : 0.9815969467163086\n",
      "step : 150/2140, loss : 1.024088678663051\n",
      "step : 300/2140, loss : 1.0418230328958253\n",
      "step : 450/2140, loss : 1.0300914674297224\n",
      "step : 600/2140, loss : 1.05297848610965\n",
      "step : 750/2140, loss : 1.0499351854228798\n",
      "step : 900/2140, loss : 1.0515141230376561\n",
      "step : 1050/2140, loss : 1.0588930589681227\n",
      "step : 1200/2140, loss : 1.0598973857590182\n",
      "step : 1350/2140, loss : 1.0617382552014023\n",
      "step : 1500/2140, loss : 1.0519791633488225\n",
      "step : 1650/2140, loss : 1.0611744828882523\n",
      "step : 1800/2140, loss : 1.062584786018486\n",
      "step : 1950/2140, loss : 1.061169040500374\n",
      "step : 2100/2140, loss : 1.065030129608709\n",
      "epoch = 3 loss = 0.7471671104431152 validation multi-class accuracy = 0.8656\n",
      "step : 0/2140, loss : 0.9947332143783569\n",
      "step : 150/2140, loss : 1.030853866921317\n",
      "step : 300/2140, loss : 1.0572996964090027\n",
      "step : 450/2140, loss : 1.0453431306767473\n",
      "step : 600/2140, loss : 1.0513778200939747\n",
      "step : 750/2140, loss : 1.04360913681727\n",
      "step : 900/2140, loss : 1.0550009202171833\n",
      "step : 1050/2140, loss : 1.0653351298853047\n",
      "step : 1200/2140, loss : 1.0509275355528587\n",
      "step : 1350/2140, loss : 1.0482186828602074\n",
      "step : 1500/2140, loss : 1.0398010980660288\n",
      "step : 1650/2140, loss : 1.0583205636497863\n",
      "step : 1800/2140, loss : 1.0339593200999284\n",
      "step : 1950/2140, loss : 1.0484156631968373\n",
      "step : 2100/2140, loss : 1.0482544938884197\n",
      "epoch = 4 loss = 0.7496263384819031 validation multi-class accuracy = 0.8728\n",
      "step : 0/2140, loss : 1.2089253664016724\n",
      "step : 150/2140, loss : 1.0835902024992237\n",
      "step : 300/2140, loss : 1.0416674043395147\n",
      "step : 450/2140, loss : 1.0309551709816953\n",
      "step : 600/2140, loss : 1.0360281359892343\n",
      "step : 750/2140, loss : 1.0559323296767937\n",
      "step : 900/2140, loss : 1.0440160566768333\n",
      "step : 1050/2140, loss : 1.0448412440234192\n",
      "step : 1200/2140, loss : 1.0345847741136223\n",
      "step : 1350/2140, loss : 1.0239816195680507\n",
      "step : 1500/2140, loss : 1.0373090135109067\n",
      "step : 1650/2140, loss : 1.0396810167266828\n",
      "step : 1800/2140, loss : 1.055298112430567\n",
      "step : 1950/2140, loss : 1.0572578016074303\n",
      "step : 2100/2140, loss : 1.0455829752116566\n",
      "epoch = 5 loss = 0.7863866686820984 validation multi-class accuracy = 0.8824\n",
      "step : 0/2140, loss : 0.9330199360847473\n",
      "step : 150/2140, loss : 1.0025998386484891\n",
      "step : 300/2140, loss : 1.0201987741613525\n",
      "step : 450/2140, loss : 1.02536773224363\n",
      "step : 600/2140, loss : 1.0371133243757942\n",
      "step : 750/2140, loss : 1.0472897924843747\n",
      "step : 900/2140, loss : 1.0383901604078862\n",
      "step : 1050/2140, loss : 1.0352566175193016\n",
      "step : 1200/2140, loss : 1.0222606951068456\n",
      "step : 1350/2140, loss : 1.0418205750362541\n",
      "step : 1500/2140, loss : 1.0240098370359456\n",
      "step : 1650/2140, loss : 1.0204561124801927\n",
      "step : 1800/2140, loss : 1.033505385605003\n",
      "step : 1950/2140, loss : 1.0320906164678512\n",
      "step : 2100/2140, loss : 1.0482589860194431\n",
      "epoch = 6 loss = 0.8687068819999695 validation multi-class accuracy = 0.8775\n",
      "step : 0/2140, loss : 0.964645266532898\n",
      "step : 150/2140, loss : 1.0036586539887389\n",
      "step : 300/2140, loss : 1.0166611618540584\n",
      "step : 450/2140, loss : 1.0352130776649187\n",
      "step : 600/2140, loss : 1.0365219598720021\n",
      "step : 750/2140, loss : 1.0315163076496259\n",
      "step : 900/2140, loss : 1.0262644439103101\n",
      "step : 1050/2140, loss : 1.0402353511310598\n",
      "step : 1200/2140, loss : 1.0377950659161757\n",
      "step : 1350/2140, loss : 1.0201088603588135\n",
      "step : 1500/2140, loss : 1.0202935546909349\n",
      "step : 1650/2140, loss : 1.0399926866709097\n",
      "step : 1800/2140, loss : 1.0344032584197898\n",
      "step : 1950/2140, loss : 1.0382666429794005\n",
      "step : 2100/2140, loss : 1.0548856836127345\n",
      "epoch = 7 loss = 0.6944710612297058 validation multi-class accuracy = 0.8600\n",
      "step : 0/2140, loss : 1.2151575088500977\n",
      "step : 150/2140, loss : 1.0623844875316237\n",
      "step : 300/2140, loss : 1.0185204076491128\n",
      "step : 450/2140, loss : 1.0340280697050364\n",
      "step : 600/2140, loss : 1.0315314265453777\n",
      "step : 750/2140, loss : 1.0126440432863064\n",
      "step : 900/2140, loss : 1.0401870063850622\n",
      "step : 1050/2140, loss : 1.0124885474239578\n",
      "step : 1200/2140, loss : 1.031949858583953\n",
      "step : 1350/2140, loss : 1.0412831949348897\n",
      "step : 1500/2140, loss : 1.0434183812578244\n",
      "step : 1650/2140, loss : 1.0360298219247692\n",
      "step : 1800/2140, loss : 1.037267108471465\n",
      "step : 1950/2140, loss : 1.030066881519083\n",
      "step : 2100/2140, loss : 1.03241775822082\n",
      "epoch = 8 loss = 0.9537258148193359 validation multi-class accuracy = 0.8862\n",
      "step : 0/2140, loss : 1.000163197517395\n",
      "step : 150/2140, loss : 1.0082549909269076\n",
      "step : 300/2140, loss : 1.02385929795035\n",
      "step : 450/2140, loss : 1.0264132870088396\n",
      "step : 600/2140, loss : 1.0096184584815495\n",
      "step : 750/2140, loss : 1.0305832138771378\n",
      "step : 900/2140, loss : 1.0187632276862526\n",
      "step : 1050/2140, loss : 1.0213385633236671\n",
      "step : 1200/2140, loss : 1.03811817329268\n",
      "step : 1350/2140, loss : 1.0235457686823177\n",
      "step : 1500/2140, loss : 1.0246690506145293\n",
      "step : 1650/2140, loss : 1.0185214325548406\n",
      "step : 1800/2140, loss : 1.0215747625316844\n",
      "step : 1950/2140, loss : 1.0167236203224979\n",
      "step : 2100/2140, loss : 1.0192435354542948\n",
      "epoch = 9 loss = 0.8611214756965637 validation multi-class accuracy = 0.8759\n",
      "step : 0/2140, loss : 0.9779963493347168\n",
      "step : 150/2140, loss : 0.9996370499784408\n",
      "step : 300/2140, loss : 1.0038428181702292\n",
      "step : 450/2140, loss : 1.0146893961356223\n",
      "step : 600/2140, loss : 1.0145500784721138\n",
      "step : 750/2140, loss : 1.0126364678465851\n",
      "step : 900/2140, loss : 1.0142387058098172\n",
      "step : 1050/2140, loss : 1.0225760419523222\n",
      "step : 1200/2140, loss : 1.029383830359301\n",
      "step : 1350/2140, loss : 1.0073465735999445\n",
      "step : 1500/2140, loss : 1.0292645585069278\n",
      "step : 1650/2140, loss : 1.0163169395104648\n",
      "step : 1800/2140, loss : 1.01367196873904\n",
      "step : 1950/2140, loss : 1.028001352979258\n",
      "step : 2100/2140, loss : 1.0331074481108715\n",
      "epoch = 10 loss = 0.7434759140014648 validation multi-class accuracy = 0.8738\n",
      "step : 0/2140, loss : 0.93091881275177\n",
      "step : 150/2140, loss : 0.9926689668597422\n",
      "step : 300/2140, loss : 1.002622194891274\n",
      "step : 450/2140, loss : 0.9916006694448894\n",
      "step : 600/2140, loss : 1.002618594274339\n",
      "step : 750/2140, loss : 1.013766175493811\n",
      "step : 900/2140, loss : 1.011862522541189\n",
      "step : 1050/2140, loss : 1.0282697732480643\n",
      "step : 1200/2140, loss : 1.0184294197209958\n",
      "step : 1350/2140, loss : 1.0321453976522577\n",
      "step : 1500/2140, loss : 1.022584562881885\n",
      "step : 1650/2140, loss : 1.0084772156978612\n",
      "step : 1800/2140, loss : 1.0083620063882834\n",
      "step : 1950/2140, loss : 1.0195543132266025\n",
      "step : 2100/2140, loss : 1.0111863252777118\n",
      "epoch = 11 loss = 0.4990788400173187 validation multi-class accuracy = 0.8756\n",
      "epoch = 11 loss = 0.7380571961402893 validation multi-class accuracy = 0.8990\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "     # for training only, need nightly build pytorch\n",
    "\n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "        # we'll train fold 0 first\n",
    "        # if fold > 0:\n",
    "        #     break \n",
    "\n",
    "        print('Training with {} started'.format(fold))\n",
    "\n",
    "        print(len(trn_idx), len(val_idx))\n",
    "        train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx, data_root='./cassava-leaf-disease-classification/train_images/')\n",
    "\n",
    "        device = torch.device(CFG['device'])\n",
    "        \n",
    "        model = CassvaImgClassifier_ViT(CFG['model_arch'], train.label.nunique(), pretrained=True).to(device)\n",
    "        freeze_batchnorm_stats(model)\n",
    "        \n",
    "        scaler = GradScaler()   \n",
    "        #base_opt = torch.optim.AdamW(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
    "        base_opt = AdamP(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
    "        optimizer = SWA(base_opt, swa_start=15, swa_freq=1, swa_lr=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CFG['T_0'], T_mult=1, eta_min=CFG['min_lr'], last_epoch=-1)\n",
    "        \n",
    "        #loss_tr = LabelSmoothingLoss(classes=CFG['target_size'], smoothing=CFG['smoothing']).to(device)\n",
    "        loss_tr = LabelSmoothingCrossEntropy(smoothing=CFG['smoothing'])\n",
    "        # loss_tr = nn.CrossEntropyLoss().to(device) #MyCrossEntropyLoss().to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "        \n",
    "        for epoch in range(CFG['epochs']):\n",
    "            if epoch == CFG['freeze_bn_epochs']:\n",
    "                unfreeze_batchnorm_stats(model)\n",
    "                \n",
    "                \n",
    "            train_one_epoch(epoch, model, loss_tr, optimizer, train_loader, device, scheduler=scheduler, schd_batch_update=False)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False)\n",
    "\n",
    "            torch.save(model.state_dict(),'./{}/{}_fold_{}_{}'.format(CFG['model_path'], CFG['model_arch'], fold, epoch)) \n",
    "        optimizer.swap_swa_sgd()\n",
    "        optimizer.bn_update(train_loader, model, device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False)\n",
    "            torch.save(model.state_dict(),'./{}/swa_{}_fold_{}_{}'.format(CFG['model_path'], CFG['model_arch'], fold, epoch)) \n",
    "        #torch.save(model.cnn_model.state_dict(),'{}/cnn_model_fold_{}_{}'.format(CFG['model_path'], fold, CFG['tag']))\n",
    "        del model, optimizer, train_loader, val_loader, scaler, scheduler\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7680"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512 * 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 8637.721674,
   "end_time": "2020-11-23T15:56:40.428882",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-23T13:32:42.707208",
   "version": "2.1.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
