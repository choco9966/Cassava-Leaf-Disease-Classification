{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "papermill": {
      "duration": 8637.721674,
      "end_time": "2020-11-23T15:56:40.428882",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-11-23T13:32:42.707208",
      "version": "2.1.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "[VIT]Baseline_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfzMKdMqkM2r"
      },
      "source": [
        "import os \r\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # specify GPUs locally"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "papermill": {
          "duration": 2.173722,
          "end_time": "2020-11-23T13:32:49.521795",
          "exception": false,
          "start_time": "2020-11-23T13:32:47.348073",
          "status": "completed"
        },
        "tags": [],
        "id": "Q_theIgIjba1"
      },
      "source": [
        "from glob import glob\n",
        "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
        "import cv2\n",
        "from skimage import io\n",
        "import torch\n",
        "from torch import nn\n",
        "import os\n",
        "from datetime import datetime\n",
        "import time\n",
        "import random\n",
        "import cv2\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from adamp import AdamP\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.nn.modules.loss import _WeightedLoss\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import timm\n",
        "\n",
        "import sklearn\n",
        "import warnings\n",
        "import joblib\n",
        "from sklearn.metrics import roc_auc_score, log_loss\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "import cv2\n",
        "#from efficientnet_pytorch import EfficientNet\n",
        "from scipy.ndimage.interpolation import zoom"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.026635,
          "end_time": "2020-11-23T13:32:49.570638",
          "exception": false,
          "start_time": "2020-11-23T13:32:49.544003",
          "status": "completed"
        },
        "tags": [],
        "id": "SPmdQbvhjba5"
      },
      "source": [
        "CFG = {\n",
        "    'fold_num': 5,\n",
        "    'seed': 719,\n",
        "    'model_arch': 'vit_base_patch16_384',\n",
        "    'model_path': 'vit_20ep',\n",
        "    'img_size': 384,\n",
        "    'epochs': 20,\n",
        "    'train_bs': 16,\n",
        "    'valid_bs': 8,\n",
        "    'T_0': 10,\n",
        "    'lr': 1e-4,\n",
        "    'min_lr': 1e-6,\n",
        "    'weight_decay':1e-6,\n",
        "    # 'freeze_bn_epochs': 5,\n",
        "    'num_workers': 4,\n",
        "    'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
        "    'verbose_step': 1,\n",
        "    'device': 'cuda:0',\n",
        "    'target_size' : 5, \n",
        "    'smoothing' : 0.3\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scwd9udrjba5"
      },
      "source": [
        "if not os.path.exists(CFG['model_path']):\n",
        "    os.makedirs(CFG['model_path'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "papermill": {
          "duration": 0.057123,
          "end_time": "2020-11-23T13:32:49.643710",
          "exception": false,
          "start_time": "2020-11-23T13:32:49.586587",
          "status": "completed"
        },
        "tags": [],
        "id": "eTlAARuqjba6",
        "outputId": "15d16b52-7fdb-4e24-e5bc-3a3a200af813"
      },
      "source": [
        "train = pd.read_csv('./input/cassava-leaf-disease-classification/merged.csv')\n",
        "\n",
        "delete_id = []\n",
        "delete_id += ['2947932468.jpg', '2252529694.jpg', '2278017076.jpg']\n",
        "train = train[~train['image_id'].isin(delete_id)].reset_index(drop=True)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000015157.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000201771.jpg</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100042118.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000723321.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000812911.jpg</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         image_id  label\n",
              "0  1000015157.jpg      0\n",
              "1  1000201771.jpg      3\n",
              "2   100042118.jpg      1\n",
              "3  1000723321.jpg      1\n",
              "4  1000812911.jpg      3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.028528,
          "end_time": "2020-11-23T13:32:49.688153",
          "exception": false,
          "start_time": "2020-11-23T13:32:49.659625",
          "status": "completed"
        },
        "tags": [],
        "id": "JscJ4jumjba6",
        "outputId": "fe72b642-0f24-4683-c2ad-e305222f7765"
      },
      "source": [
        "train.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    13192\n",
              "4     2553\n",
              "2     2374\n",
              "1     2186\n",
              "0     1089\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.016085,
          "end_time": "2020-11-23T13:32:49.720073",
          "exception": false,
          "start_time": "2020-11-23T13:32:49.703988",
          "status": "completed"
        },
        "tags": [],
        "id": "x6JmCCzXjba7"
      },
      "source": [
        "> We could do stratified validation split in each fold to make each fold's train and validation set looks like the whole train set in target distributions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.032053,
          "end_time": "2020-11-23T13:32:49.768481",
          "exception": false,
          "start_time": "2020-11-23T13:32:49.736428",
          "status": "completed"
        },
        "tags": [],
        "id": "iYxtZwmFjba7",
        "outputId": "f2d82dad-3802-44b9-be45-9f9e4d57be4f"
      },
      "source": [
        "submission = pd.read_csv('./input/cassava-leaf-disease-classification/sample_submission.csv')\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2216849948.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         image_id  label\n",
              "0  2216849948.jpg      4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.015931,
          "end_time": "2020-11-23T13:32:49.801027",
          "exception": false,
          "start_time": "2020-11-23T13:32:49.785096",
          "status": "completed"
        },
        "tags": [],
        "id": "u8gBgh5Tjba7"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.315262,
          "end_time": "2020-11-23T13:32:50.132792",
          "exception": false,
          "start_time": "2020-11-23T13:32:49.817530",
          "status": "completed"
        },
        "tags": [],
        "id": "bDtZkP6Ajba7"
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    \n",
        "def get_img(path):\n",
        "    im_bgr = cv2.imread(path)\n",
        "    im_rgb = im_bgr[:, :, ::-1]\n",
        "    #print(im_rgb)\n",
        "    return im_rgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.021311,
          "end_time": "2020-11-23T13:32:50.174973",
          "exception": false,
          "start_time": "2020-11-23T13:32:50.153662",
          "status": "completed"
        },
        "tags": [],
        "id": "eRf0y9lqjba7"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.064816,
          "end_time": "2020-11-23T13:32:50.261340",
          "exception": false,
          "start_time": "2020-11-23T13:32:50.196524",
          "status": "completed"
        },
        "tags": [],
        "id": "DzAcGAyljba8"
      },
      "source": [
        "def rand_bbox(size, lam):\n",
        "    W = size[0]\n",
        "    H = size[1]\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = np.int(W * cut_rat)\n",
        "    cut_h = np.int(H * cut_rat)\n",
        "\n",
        "    # uniform\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "    return bbx1, bby1, bbx2, bby2\n",
        "\n",
        "\n",
        "class CassavaDataset(Dataset):\n",
        "    def __init__(self, df, data_root, \n",
        "                 transforms=None, \n",
        "                 output_label=True, \n",
        "                ):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.df = df.reset_index(drop=True).copy()\n",
        "        self.transforms = transforms\n",
        "        self.data_root = data_root\n",
        "        \n",
        "        self.output_label = output_label\n",
        "        self.labels = self.df['label'].values\n",
        "\n",
        "            \n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "    \n",
        "    def __getitem__(self, index: int):\n",
        "        \n",
        "        # get labels\n",
        "        if self.output_label:\n",
        "            target = self.labels[index]\n",
        "          \n",
        "        img  = get_img(\"{}/{}\".format(self.data_root, self.df.loc[index]['image_id']))\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transforms(image=img)['image']\n",
        "        \n",
        "        if self.output_label == True:\n",
        "            return img, target\n",
        "        else:\n",
        "            return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.02183,
          "end_time": "2020-11-23T13:32:50.304795",
          "exception": false,
          "start_time": "2020-11-23T13:32:50.282965",
          "status": "completed"
        },
        "tags": [],
        "id": "EeV-ksoUjba8"
      },
      "source": [
        "# Define Train\\Validation Image Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGIC9-j5jba8"
      },
      "source": [
        "from albumentations.core.transforms_interface import DualTransform\n",
        "from albumentations.augmentations import functional as F\n",
        "class GridMask(DualTransform):\n",
        "    \"\"\"GridMask augmentation for image classification and object detection.\n",
        "    \n",
        "    Author: Qishen Ha\n",
        "    Email: haqishen@gmail.com\n",
        "    2020/01/29\n",
        "\n",
        "    Args:\n",
        "        num_grid (int): number of grid in a row or column.\n",
        "        fill_value (int, float, lisf of int, list of float): value for dropped pixels.\n",
        "        rotate ((int, int) or int): range from which a random angle is picked. If rotate is a single int\n",
        "            an angle is picked from (-rotate, rotate). Default: (-90, 90)\n",
        "        mode (int):\n",
        "            0 - cropout a quarter of the square of each grid (left top)\n",
        "            1 - reserve a quarter of the square of each grid (left top)\n",
        "            2 - cropout 2 quarter of the square of each grid (left top & right bottom)\n",
        "\n",
        "    Targets:\n",
        "        image, mask\n",
        "\n",
        "    Image types:\n",
        "        uint8, float32\n",
        "\n",
        "    Reference:\n",
        "    |  https://arxiv.org/abs/2001.04086\n",
        "    |  https://github.com/akuxcw/GridMask\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_grid=3, fill_value=0, rotate=0, mode=0, always_apply=False, p=0.5):\n",
        "        super(GridMask, self).__init__(always_apply, p)\n",
        "        if isinstance(num_grid, int):\n",
        "            num_grid = (num_grid, num_grid)\n",
        "        if isinstance(rotate, int):\n",
        "            rotate = (-rotate, rotate)\n",
        "        self.num_grid = num_grid\n",
        "        self.fill_value = fill_value\n",
        "        self.rotate = rotate\n",
        "        self.mode = mode\n",
        "        self.masks = None\n",
        "        self.rand_h_max = []\n",
        "        self.rand_w_max = []\n",
        "\n",
        "    def init_masks(self, height, width):\n",
        "        if self.masks is None:\n",
        "            self.masks = []\n",
        "            n_masks = self.num_grid[1] - self.num_grid[0] + 1\n",
        "            for n, n_g in enumerate(range(self.num_grid[0], self.num_grid[1] + 1, 1)):\n",
        "                grid_h = height / n_g\n",
        "                grid_w = width / n_g\n",
        "                this_mask = np.ones((int((n_g + 1) * grid_h), int((n_g + 1) * grid_w))).astype(np.uint8)\n",
        "                for i in range(n_g + 1):\n",
        "                    for j in range(n_g + 1):\n",
        "                        this_mask[\n",
        "                             int(i * grid_h) : int(i * grid_h + grid_h / 2),\n",
        "                             int(j * grid_w) : int(j * grid_w + grid_w / 2)\n",
        "                        ] = self.fill_value\n",
        "                        if self.mode == 2:\n",
        "                            this_mask[\n",
        "                                 int(i * grid_h + grid_h / 2) : int(i * grid_h + grid_h),\n",
        "                                 int(j * grid_w + grid_w / 2) : int(j * grid_w + grid_w)\n",
        "                            ] = self.fill_value\n",
        "                \n",
        "                if self.mode == 1:\n",
        "                    this_mask = 1 - this_mask\n",
        "\n",
        "                self.masks.append(this_mask)\n",
        "                self.rand_h_max.append(grid_h)\n",
        "                self.rand_w_max.append(grid_w)\n",
        "\n",
        "    def apply(self, image, mask, rand_h, rand_w, angle, **params):\n",
        "        h, w = image.shape[:2]\n",
        "        mask = F.rotate(mask, angle) if self.rotate[1] > 0 else mask\n",
        "        mask = mask[:,:,np.newaxis] if image.ndim == 3 else mask\n",
        "        image *= mask[rand_h:rand_h+h, rand_w:rand_w+w].astype(image.dtype)\n",
        "        return image\n",
        "\n",
        "    def get_params_dependent_on_targets(self, params):\n",
        "        img = params['image']\n",
        "        height, width = img.shape[:2]\n",
        "        self.init_masks(height, width)\n",
        "\n",
        "        mid = np.random.randint(len(self.masks))\n",
        "        mask = self.masks[mid]\n",
        "        rand_h = np.random.randint(self.rand_h_max[mid])\n",
        "        rand_w = np.random.randint(self.rand_w_max[mid])\n",
        "        angle = np.random.randint(self.rotate[0], self.rotate[1]) if self.rotate[1] > 0 else 0\n",
        "\n",
        "        return {'mask': mask, 'rand_h': rand_h, 'rand_w': rand_w, 'angle': angle}\n",
        "\n",
        "    @property\n",
        "    def targets_as_params(self):\n",
        "        return ['image']\n",
        "\n",
        "    def get_transform_init_args_names(self):\n",
        "        return ('num_grid', 'fill_value', 'rotate', 'mode')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.590042,
          "end_time": "2020-11-23T13:32:50.916225",
          "exception": false,
          "start_time": "2020-11-23T13:32:50.326183",
          "status": "completed"
        },
        "tags": [],
        "id": "bDg8hFQHjba9"
      },
      "source": [
        "from albumentations import (\n",
        "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
        "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
        "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
        "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n",
        ")\n",
        "\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "def get_train_transforms():\n",
        "    return Compose([\n",
        "            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n",
        "            Transpose(p=0.5),\n",
        "            HorizontalFlip(p=0.5),\n",
        "            VerticalFlip(p=0.5),\n",
        "            ShiftScaleRotate(p=0.5),\n",
        "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
        "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
        "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
        "            CoarseDropout(p=0.5),\n",
        "            GridMask(num_grid=3, p=0.5),\n",
        "            ToTensorV2(p=1.0),\n",
        "        ], p=1.)\n",
        "  \n",
        "        \n",
        "def get_valid_transforms():\n",
        "    return Compose([\n",
        "            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
        "            Resize(CFG['img_size'], CFG['img_size']),\n",
        "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
        "            ToTensorV2(p=1.0),\n",
        "        ], p=1.)\n",
        "\n",
        "def get_inference_transforms():\n",
        "    return Compose([\n",
        "            OneOf([\n",
        "                Resize(CFG['img_size'], CFG['img_size'], p=1.),\n",
        "                CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
        "                RandomResizedCrop(CFG['img_size'], CFG['img_size'], p=1.)\n",
        "            ], p=1.), \n",
        "            Transpose(p=0.5),\n",
        "            HorizontalFlip(p=0.5),\n",
        "            VerticalFlip(p=0.5),\n",
        "            Resize(CFG['img_size'], CFG['img_size']),\n",
        "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
        "            ToTensorV2(p=1.0),\n",
        "        ], p=1.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.024452,
          "end_time": "2020-11-23T13:32:50.962106",
          "exception": false,
          "start_time": "2020-11-23T13:32:50.937654",
          "status": "completed"
        },
        "tags": [],
        "id": "UOiJgWHljba9"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.033239,
          "end_time": "2020-11-23T13:32:51.017593",
          "exception": false,
          "start_time": "2020-11-23T13:32:50.984354",
          "status": "completed"
        },
        "tags": [],
        "id": "NQLSDDUFjba-"
      },
      "source": [
        "class CassvaImgClassifier(nn.Module):\n",
        "    def __init__(self, model_arch, n_class, pretrained=False):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
        "        n_features = self.model.classifier.in_features\n",
        "        self.model.classifier = nn.Linear(n_features, n_class)\n",
        "#         self.model.classifier = nn.Sequential(\n",
        "#             nn.Linear(n_features, n_features//2),\n",
        "#             nn.LeakyReLU(inplace=True),\n",
        "#             nn.Linear(n_features//2, n_class)\n",
        "#         )\n",
        "        \n",
        "        for module in self.model.modules():\n",
        "            #print(module)\n",
        "            if isinstance(module, nn.BatchNorm2d):\n",
        "                if hasattr(module, 'weight'):\n",
        "                    module.weight.requires_grad_(False)\n",
        "                if hasattr(module, 'bias'):\n",
        "                    module.bias.requires_grad_(False)\n",
        "                #module.eval()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oBNPoc0jba-"
      },
      "source": [
        "class CassvaImgClassifier_ViT(nn.Module):\n",
        "    def __init__(self, model_arch, n_class, pretrained=False):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
        "        #if pretrained:\n",
        "        #    self.model.load_state_dict(torch.load(MODEL_PATH))\n",
        "\n",
        "        self.model.head = nn.Linear(self.model.head.in_features, n_class)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.021054,
          "end_time": "2020-11-23T13:32:51.059722",
          "exception": false,
          "start_time": "2020-11-23T13:32:51.038668",
          "status": "completed"
        },
        "tags": [],
        "id": "VdjXlJpcjba-"
      },
      "source": [
        "# Training APIs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.061685,
          "end_time": "2020-11-23T13:32:51.144150",
          "exception": false,
          "start_time": "2020-11-23T13:32:51.082465",
          "status": "completed"
        },
        "tags": [],
        "id": "whllUNZ9jba-"
      },
      "source": [
        "def prepare_dataloader(df, trn_idx, val_idx, data_root='./input/cassava-leaf-disease-classification/train_images/'):\n",
        "    \n",
        "    # from catalyst.data.sampler import BalanceClassSampler\n",
        "    \n",
        "    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n",
        "    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n",
        "        \n",
        "    train_ds = CassavaDataset(train_, data_root, transforms=get_train_transforms(), output_label=True)\n",
        "    valid_ds = CassavaDataset(valid_, data_root, transforms=get_valid_transforms(), output_label=True)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=CFG['train_bs'],\n",
        "        pin_memory=False,\n",
        "        drop_last=False,\n",
        "        shuffle=True,        \n",
        "        num_workers=CFG['num_workers'],\n",
        "        #sampler=BalanceClassSampler(labels=train_['label'].values, mode=\"downsampling\")\n",
        "    )\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        valid_ds, \n",
        "        batch_size=CFG['valid_bs'],\n",
        "        num_workers=CFG['num_workers'],\n",
        "        shuffle=False,\n",
        "        pin_memory=False,\n",
        "    )\n",
        "    return train_loader, val_loader\n",
        "\n",
        "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None, schd_batch_update=False):\n",
        "    model.train()\n",
        "\n",
        "    t = time.time()\n",
        "    running_loss = None\n",
        "\n",
        "    # pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
        "    for step, (imgs, image_labels) in enumerate(train_loader):\n",
        "        imgs = imgs.to(device).float()\n",
        "        image_labels = image_labels.to(device).long()\n",
        "\n",
        "        with autocast():\n",
        "            image_preds = model(imgs)   #output = model(input)\n",
        "            loss = loss_fn(image_preds, image_labels)\n",
        "            \n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            if running_loss is None:\n",
        "                running_loss = loss.item()\n",
        "            else:\n",
        "                running_loss = running_loss * .99 + loss.item() * .01\n",
        "\n",
        "            if ((step + 1) %  CFG['accum_iter'] == 0) or ((step + 1) == len(train_loader)):\n",
        "\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad() \n",
        "                \n",
        "                if scheduler is not None and schd_batch_update:\n",
        "                    scheduler.step()\n",
        "\n",
        "    if scheduler is not None and not schd_batch_update:\n",
        "        scheduler.step()\n",
        "        \n",
        "def valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n",
        "    model.eval()\n",
        "\n",
        "    t = time.time()\n",
        "    loss_sum = 0\n",
        "    sample_num = 0\n",
        "    image_preds_all = []\n",
        "    image_targets_all = []\n",
        "    \n",
        "    # pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
        "    for step, (imgs, image_labels) in enumerate(val_loader):\n",
        "        imgs = imgs.to(device).float()\n",
        "        image_labels = image_labels.to(device).long()\n",
        "        \n",
        "        image_preds = model(imgs)   #output = model(input)\n",
        "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
        "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
        "        \n",
        "        loss = loss_fn(image_preds, image_labels)\n",
        "        \n",
        "        loss_sum += loss.item()*image_labels.shape[0]\n",
        "        sample_num += image_labels.shape[0]  \n",
        "\n",
        "        # if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(val_loader)):\n",
        "        #     description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n",
        "        #     pbar.set_description(description)\n",
        "    \n",
        "    image_preds_all = np.concatenate(image_preds_all)\n",
        "    image_targets_all = np.concatenate(image_targets_all)\n",
        "    print('epoch = {}'.format(epoch+1), 'validation multi-class accuracy = {:.4f}'.format((image_preds_all==image_targets_all).mean()))\n",
        "    \n",
        "    if scheduler is not None:\n",
        "        if schd_loss_update:\n",
        "            scheduler.step(loss_sum/sample_num)\n",
        "        else:\n",
        "            scheduler.step()\n",
        "        \n",
        "def inference_one_epoch(model, data_loader, device):\n",
        "    model.eval()\n",
        "    image_preds_all = []\n",
        "    # pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
        "    with torch.no_grad():\n",
        "        for step, (imgs, _labels) in enumerate(data_loader):\n",
        "            imgs = imgs.to(device).float()\n",
        "\n",
        "            image_preds = model(imgs)   #output = model(input)\n",
        "            image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
        "        \n",
        "    \n",
        "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
        "    return image_preds_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP1I2Gv6jba_"
      },
      "source": [
        "def freeze_batchnorm_stats(net):\n",
        "    net.train()\n",
        "    try:\n",
        "        for m in net.modules():\n",
        "            if isinstance(m,nn.BatchNorm2d) or isinstance(m,nn.LayerNorm):\n",
        "                m.eval()\n",
        "    except ValuError:\n",
        "        print('error with batchnorm2d or layernorm')\n",
        "        return\n",
        "    \n",
        "def unfreeze_batchnorm_stats(net):\n",
        "    net.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.034873,
          "end_time": "2020-11-23T13:32:51.200704",
          "exception": false,
          "start_time": "2020-11-23T13:32:51.165831",
          "status": "completed"
        },
        "tags": [],
        "id": "GF7UkBQIjba_"
      },
      "source": [
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    \"\"\"\n",
        "    NLL loss with label smoothing.\n",
        "    \"\"\"\n",
        "    def __init__(self, smoothing=0.1):\n",
        "        \"\"\"\n",
        "        Constructor for the LabelSmoothing module.\n",
        "        :param smoothing: label smoothing factor\n",
        "        \"\"\"\n",
        "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
        "        assert smoothing < 1.0\n",
        "        self.smoothing = smoothing\n",
        "        self.confidence = 1. - smoothing\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n",
        "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
        "        nll_loss = nll_loss.squeeze(1)\n",
        "        smooth_loss = -logprobs.mean(dim=-1)\n",
        "        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
        "        return loss.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB0L50WYjba_"
      },
      "source": [
        "# ====================================================\n",
        "# Label Smoothing\n",
        "# ====================================================\n",
        "class LabelSmoothingLoss(nn.Module): \n",
        "    def __init__(self, classes, smoothing=0.0, dim=-1): \n",
        "        super(LabelSmoothingLoss, self).__init__() \n",
        "        self.confidence = 1.0 - smoothing \n",
        "        self.smoothing = smoothing \n",
        "        self.cls = classes \n",
        "        self.dim = dim \n",
        "        \n",
        "    def forward(self, pred, target): \n",
        "        pred = pred.log_softmax(dim=self.dim) \n",
        "        with torch.no_grad():\n",
        "            true_dist = torch.zeros_like(pred) \n",
        "            true_dist.fill_(self.smoothing / (self.cls - 1)) \n",
        "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence) \n",
        "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.020806,
          "end_time": "2020-11-23T13:32:51.243006",
          "exception": false,
          "start_time": "2020-11-23T13:32:51.222200",
          "status": "completed"
        },
        "tags": [],
        "id": "UdovXYnWjba_"
      },
      "source": [
        "# Main Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIPZxSL9jba_"
      },
      "source": [
        "from torchcontrib.optim import SWA\r\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-5XuV1RkHXV"
      },
      "source": [
        "for c in range(5): \r\n",
        "    train[c] = 0\r\n",
        "\r\n",
        "folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\r\n",
        "for fold, (trn_idx, val_idx) in enumerate(folds):\r\n",
        "    print('Training with {} started'.format(fold))\r\n",
        "    print(len(trn_idx), len(val_idx))\r\n",
        "    train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx, data_root='./input/cassava-leaf-disease-classification/train/')\r\n",
        "\r\n",
        "    device = torch.device(CFG['device'])\r\n",
        "\r\n",
        "    model = CassvaImgClassifier_ViT(CFG['model_arch'], train.label.nunique(), pretrained=True).to(device)\r\n",
        "\r\n",
        "    scaler = GradScaler()   \r\n",
        "    base_opt = AdamP(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\r\n",
        "    # base_opt = torch.optim.Adam(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\r\n",
        "    optimizer = SWA(base_opt, swa_start=2*len(trn_idx)//CFG['train_bs'], swa_freq=len(trn_idx)//CFG['train_bs'])\r\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CFG['T_0'], T_mult=1, eta_min=CFG['min_lr'], last_epoch=-1)\r\n",
        "\r\n",
        "    loss_tr = LabelSmoothingLoss(classes=CFG['target_size'], smoothing=CFG['smoothing']).to(device)\r\n",
        "    loss_fn = nn.CrossEntropyLoss().to(device)\r\n",
        "\r\n",
        "    for epoch in range(CFG['epochs']):\r\n",
        "        train_one_epoch(epoch, model, loss_tr, optimizer, train_loader, device, scheduler=scheduler, schd_batch_update=False)\r\n",
        "\r\n",
        "        with torch.no_grad():\r\n",
        "            valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False)\r\n",
        "    optimizer.swap_swa_sgd()\r\n",
        "    optimizer.bn_update(train_loader, model, device)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False)\r\n",
        "        torch.save(model.state_dict(),'./{}/swa_{}_fold_{}_{}'.format(CFG['model_path'],CFG['model_arch'], fold, epoch)) \r\n",
        "\r\n",
        "    tst_preds = []\r\n",
        "    for tta in range(5):\r\n",
        "        tst_preds += [inference_one_epoch(model, val_loader, device)]\r\n",
        "\r\n",
        "    train.loc[val_idx, [0, 1, 2, 3, 4]] = np.mean(tst_preds, axis=0)\r\n",
        "\r\n",
        "    del model, optimizer, train_loader, val_loader, scaler, scheduler\r\n",
        "    torch.cuda.empty_cache()\r\n",
        "\r\n",
        "train['pred'] = np.array(train[[0, 1, 2, 3, 4]]).argmax(axis=1)\r\n",
        "print(accuracy_score(train['label'].values, train['pred'].values))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}