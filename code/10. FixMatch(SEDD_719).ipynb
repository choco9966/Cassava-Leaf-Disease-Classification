{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO-DO LIST \n",
    "- Label Smoothing \n",
    "    - https://www.kaggle.com/chocozzz/train-cassava-starter-using-label-smoothing\n",
    "    - https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/173733\n",
    "    \n",
    "- Class Imbalance \n",
    "\n",
    "- SWA / SWAG \n",
    "\n",
    "- Augmentation \n",
    "    - https://www.kaggle.com/sachinprabhu/pytorch-resnet50-snapmix-train-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cassava-leaf-disease-classification', 'cassava-disease']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"./input/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T13:32:46.689286Z",
     "iopub.status.busy": "2020-11-23T13:32:46.688477Z",
     "iopub.status.idle": "2020-11-23T13:32:47.332282Z",
     "shell.execute_reply": "2020-11-23T13:32:47.331626Z"
    },
    "papermill": {
     "duration": 0.664524,
     "end_time": "2020-11-23T13:32:47.332411",
     "exception": false,
     "start_time": "2020-11-23T13:32:46.667887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "package_paths = [\n",
    "    './input/pytorch-image-models/pytorch-image-models-master', #'../input/efficientnet-pytorch-07/efficientnet_pytorch-0.7.0'\n",
    "    './input/pytorch-gradual-warmup-lr-master'\n",
    "]\n",
    "import sys; \n",
    "\n",
    "for pth in package_paths:\n",
    "    sys.path.append(pth)\n",
    "    \n",
    "# from warmup_scheduler import GradualWarmupScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-23T13:32:47.374999Z",
     "iopub.status.busy": "2020-11-23T13:32:47.374085Z",
     "iopub.status.idle": "2020-11-23T13:32:49.520134Z",
     "shell.execute_reply": "2020-11-23T13:32:49.521535Z"
    },
    "papermill": {
     "duration": 2.173722,
     "end_time": "2020-11-23T13:32:49.521795",
     "exception": false,
     "start_time": "2020-11-23T13:32:47.348073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "import cv2\n",
    "from skimage import io\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import timm\n",
    "from adamp import AdamP\n",
    "\n",
    "import sklearn\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import cv2\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "##SWA\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR, update_bn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T13:32:49.569017Z",
     "iopub.status.busy": "2020-11-23T13:32:49.566882Z",
     "iopub.status.idle": "2020-11-23T13:32:49.569892Z",
     "shell.execute_reply": "2020-11-23T13:32:49.570496Z"
    },
    "papermill": {
     "duration": 0.026635,
     "end_time": "2020-11-23T13:32:49.570638",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.544003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 719,\n",
    "    'model_arch': 'tf_efficientnet_b4_ns',\n",
    "    'img_size': 512,\n",
    "    'epochs': 7,\n",
    "    'train_bs': 9,\n",
    "    'valid_bs': 16,\n",
    "    'T_0': 10,\n",
    "    'lr': 4e-4,\n",
    "    'min_lr': 3e-5,\n",
    "    'weight_decay':1e-6,\n",
    "    'num_workers': 4,\n",
    "    'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "    'verbose_step': 1,\n",
    "    'device': 'cuda:0',\n",
    "    'target_size' : 5,\n",
    "    'smoothing' : 0.2,\n",
    "    'swa_start_epoch' : 2,\n",
    "    ## Following four are related to FixMatch\n",
    "    'mu' : 2,\n",
    "    'T' : 1,          # temperature\n",
    "    'lambda_u' : 1.,\n",
    "    'threshold' : 0.85,\n",
    "    ##\n",
    "    'debug' : False \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-23T13:32:49.608239Z",
     "iopub.status.busy": "2020-11-23T13:32:49.607314Z",
     "iopub.status.idle": "2020-11-23T13:32:49.643095Z",
     "shell.execute_reply": "2020-11-23T13:32:49.643555Z"
    },
    "papermill": {
     "duration": 0.057123,
     "end_time": "2020-11-23T13:32:49.643710",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.586587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  1000015157.jpg      0\n",
       "1  1000201771.jpg      3\n",
       "2   100042118.jpg      1\n",
       "3  1000723321.jpg      1\n",
       "4  1000812911.jpg      3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./input/cassava-leaf-disease-classification/train.csv')\n",
    "delete_id = ['2947932468.jpg', '2252529694.jpg', '2278017076.jpg']\n",
    "train = train[~train['image_id'].isin(delete_id)].reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016085,
     "end_time": "2020-11-23T13:32:49.720073",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.703988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> We could do stratified validation split in each fold to make each fold's train and validation set looks like the whole train set in target distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T13:32:49.758043Z",
     "iopub.status.busy": "2020-11-23T13:32:49.757132Z",
     "iopub.status.idle": "2020-11-23T13:32:49.768355Z",
     "shell.execute_reply": "2020-11-23T13:32:49.767792Z"
    },
    "papermill": {
     "duration": 0.032053,
     "end_time": "2020-11-23T13:32:49.768481",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.736428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  2216849948.jpg      4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('./input/cassava-leaf-disease-classification/sample_submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015931,
     "end_time": "2020-11-23T13:32:49.801027",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.785096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T13:32:49.842576Z",
     "iopub.status.busy": "2020-11-23T13:32:49.841805Z",
     "iopub.status.idle": "2020-11-23T13:32:50.132101Z",
     "shell.execute_reply": "2020-11-23T13:32:50.132613Z"
    },
    "papermill": {
     "duration": 0.315262,
     "end_time": "2020-11-23T13:32:50.132792",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.817530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    #print(im_rgb)\n",
    "    return im_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021311,
     "end_time": "2020-11-23T13:32:50.174973",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.153662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T13:32:50.258373Z",
     "iopub.status.busy": "2020-11-23T13:32:50.237779Z",
     "iopub.status.idle": "2020-11-23T13:32:50.261225Z",
     "shell.execute_reply": "2020-11-23T13:32:50.260667Z"
    },
    "papermill": {
     "duration": 0.064816,
     "end_time": "2020-11-23T13:32:50.261340",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.196524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[0]\n",
    "    H = size[1]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, df, data_root, \n",
    "                 transforms=None, \n",
    "                 output_label=True, \n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transforms = transforms\n",
    "        self.data_root = data_root\n",
    "        \n",
    "        self.output_label = output_label\n",
    "        self.labels = self.df['label'].values\n",
    "\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # get labels\n",
    "        if self.output_label:\n",
    "            target = self.labels[index]\n",
    "          \n",
    "        img  = get_img(\"{}/{}\".format(self.data_root, self.df.loc[index]['image_id']))\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "        \n",
    "        if self.output_label == True:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02183,
     "end_time": "2020-11-23T13:32:50.304795",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.282965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Train\\Validation Image Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations.core.transforms_interface import DualTransform\n",
    "# from albumentations.augmentations import functional as F\n",
    "class GridMask(DualTransform):\n",
    "    \"\"\"GridMask augmentation for image classification and object detection.\n",
    "    \n",
    "    Author: Qishen Ha\n",
    "    Email: haqishen@gmail.com\n",
    "    2020/01/29\n",
    "\n",
    "    Args:\n",
    "        num_grid (int): number of grid in a row or column.\n",
    "        fill_value (int, float, lisf of int, list of float): value for dropped pixels.\n",
    "        rotate ((int, int) or int): range from which a random angle is picked. If rotate is a single int\n",
    "            an angle is picked from (-rotate, rotate). Default: (-90, 90)\n",
    "        mode (int):\n",
    "            0 - cropout a quarter of the square of each grid (left top)\n",
    "            1 - reserve a quarter of the square of each grid (left top)\n",
    "            2 - cropout 2 quarter of the square of each grid (left top & right bottom)\n",
    "\n",
    "    Targets:\n",
    "        image, mask\n",
    "\n",
    "    Image types:\n",
    "        uint8, float32\n",
    "\n",
    "    Reference:\n",
    "    |  https://arxiv.org/abs/2001.04086\n",
    "    |  https://github.com/akuxcw/GridMask\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_grid=3, fill_value=0, rotate=0, mode=0, always_apply=False, p=0.5):\n",
    "        super(GridMask, self).__init__(always_apply, p)\n",
    "        if isinstance(num_grid, int):\n",
    "            num_grid = (num_grid, num_grid)\n",
    "        if isinstance(rotate, int):\n",
    "            rotate = (-rotate, rotate)\n",
    "        self.num_grid = num_grid\n",
    "        self.fill_value = fill_value\n",
    "        self.rotate = rotate\n",
    "        self.mode = mode\n",
    "        self.masks = None\n",
    "        self.rand_h_max = []\n",
    "        self.rand_w_max = []\n",
    "\n",
    "    def init_masks(self, height, width):\n",
    "        if self.masks is None:\n",
    "            self.masks = []\n",
    "            n_masks = self.num_grid[1] - self.num_grid[0] + 1\n",
    "            for n, n_g in enumerate(range(self.num_grid[0], self.num_grid[1] + 1, 1)):\n",
    "                grid_h = height / n_g\n",
    "                grid_w = width / n_g\n",
    "                this_mask = np.ones((int((n_g + 1) * grid_h), int((n_g + 1) * grid_w))).astype(np.uint8)\n",
    "                for i in range(n_g + 1):\n",
    "                    for j in range(n_g + 1):\n",
    "                        this_mask[\n",
    "                             int(i * grid_h) : int(i * grid_h + grid_h / 2),\n",
    "                             int(j * grid_w) : int(j * grid_w + grid_w / 2)\n",
    "                        ] = self.fill_value\n",
    "                        if self.mode == 2:\n",
    "                            this_mask[\n",
    "                                 int(i * grid_h + grid_h / 2) : int(i * grid_h + grid_h),\n",
    "                                 int(j * grid_w + grid_w / 2) : int(j * grid_w + grid_w)\n",
    "                            ] = self.fill_value\n",
    "                \n",
    "                if self.mode == 1:\n",
    "                    this_mask = 1 - this_mask\n",
    "\n",
    "                self.masks.append(this_mask)\n",
    "                self.rand_h_max.append(grid_h)\n",
    "                self.rand_w_max.append(grid_w)\n",
    "\n",
    "    def apply(self, image, mask, rand_h, rand_w, angle, **params):\n",
    "        h, w = image.shape[:2]\n",
    "        mask = F.rotate(mask, angle) if self.rotate[1] > 0 else mask\n",
    "        mask = mask[:,:,np.newaxis] if image.ndim == 3 else mask\n",
    "        image *= mask[rand_h:rand_h+h, rand_w:rand_w+w].astype(image.dtype)\n",
    "        return image\n",
    "\n",
    "    def get_params_dependent_on_targets(self, params):\n",
    "        img = params['image']\n",
    "        height, width = img.shape[:2]\n",
    "        self.init_masks(height, width)\n",
    "\n",
    "        mid = np.random.randint(len(self.masks))\n",
    "        mask = self.masks[mid]\n",
    "        rand_h = np.random.randint(self.rand_h_max[mid])\n",
    "        rand_w = np.random.randint(self.rand_w_max[mid])\n",
    "        angle = np.random.randint(self.rotate[0], self.rotate[1]) if self.rotate[1] > 0 else 0\n",
    "\n",
    "        return {'mask': mask, 'rand_h': rand_h, 'rand_w': rand_w, 'angle': angle}\n",
    "\n",
    "    @property\n",
    "    def targets_as_params(self):\n",
    "        return ['image']\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return ('num_grid', 'fill_value', 'rotate', 'mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T13:32:50.363176Z",
     "iopub.status.busy": "2020-11-23T13:32:50.362365Z",
     "iopub.status.idle": "2020-11-23T13:32:50.916105Z",
     "shell.execute_reply": "2020-11-23T13:32:50.914618Z"
    },
    "papermill": {
     "duration": 0.590042,
     "end_time": "2020-11-23T13:32:50.916225",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.326183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n",
    ")\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def get_train_transforms():\n",
    "    return Compose([\n",
    "            OneOf([\n",
    "                Resize(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "                CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "                RandomResizedCrop(CFG['img_size'], CFG['img_size'], p=1.)\n",
    "            ], p=1.), \n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            ShiftScaleRotate(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            CoarseDropout(p=0.5),\n",
    "            GridMask(num_grid=3, p=0.5),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "  \n",
    "        \n",
    "def get_valid_transforms():\n",
    "    return Compose([\n",
    "            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "            Resize(CFG['img_size'], CFG['img_size']),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "\n",
    "def get_inference_transforms():\n",
    "    return Compose([\n",
    "            OneOf([\n",
    "                Resize(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "                CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "                RandomResizedCrop(CFG['img_size'], CFG['img_size'], p=1.)\n",
    "            ], p=1.), \n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            Resize(CFG['img_size'], CFG['img_size']),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024452,
     "end_time": "2020-11-23T13:32:50.962106",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.937654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T13:32:51.016348Z",
     "iopub.status.busy": "2020-11-23T13:32:51.014464Z",
     "iopub.status.idle": "2020-11-23T13:32:51.017006Z",
     "shell.execute_reply": "2020-11-23T13:32:51.017474Z"
    },
    "papermill": {
     "duration": 0.033239,
     "end_time": "2020-11-23T13:32:51.017593",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.984354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024452,
     "end_time": "2020-11-23T13:32:50.962106",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.937654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# For FixMatch Unlabeled DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>extra-image-14629.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>extra-image-8040.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>extra-image-8134.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>extra-image-7346.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train-cbsd-989.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                image_id label\n",
       "0  extra-image-14629.jpg     1\n",
       "1   extra-image-8040.jpg     1\n",
       "2   extra-image-8134.jpg     1\n",
       "3   extra-image-7346.jpg     1\n",
       "4     train-cbsd-989.jpg     1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######\n",
    "o = os.listdir('./input/cassava-disease/all/')\n",
    "o = np.array([o]).T\n",
    "label_col = np.ones_like(o)\n",
    "o = np.concatenate((o,label_col),axis=1)\n",
    "unlabeled = pd.DataFrame(o,columns=['image_id','label'])\n",
    "unlabeled.head()\n",
    "# unlabeled = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import PIL.ImageOps\n",
    "import PIL.ImageEnhance\n",
    "import PIL.ImageDraw\n",
    "from PIL import Image\n",
    "\n",
    "PARAMETER_MAX = 10\n",
    "\n",
    "\n",
    "def AutoContrast(img, **kwarg):\n",
    "    return PIL.ImageOps.autocontrast(img)\n",
    "\n",
    "\n",
    "def Brightness(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    return PIL.ImageEnhance.Brightness(img).enhance(v)\n",
    "\n",
    "\n",
    "def Color(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    return PIL.ImageEnhance.Color(img).enhance(v)\n",
    "\n",
    "\n",
    "def Contrast(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    return PIL.ImageEnhance.Contrast(img).enhance(v)\n",
    "\n",
    "\n",
    "def Cutout(img, v, max_v, bias=0):\n",
    "    if v == 0:\n",
    "        return img\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    v = int(v * min(img.size))\n",
    "    return CutoutAbs(img, v)\n",
    "\n",
    "\n",
    "def CutoutAbs(img, v, **kwarg):\n",
    "    w, h = img.size\n",
    "    x0 = np.random.uniform(0, w)\n",
    "    y0 = np.random.uniform(0, h)\n",
    "    x0 = int(max(0, x0 - v / 2.))\n",
    "    y0 = int(max(0, y0 - v / 2.))\n",
    "    x1 = int(min(w, x0 + v))\n",
    "    y1 = int(min(h, y0 + v))\n",
    "    xy = (x0, y0, x1, y1)\n",
    "    # gray\n",
    "    color = (127, 127, 127)\n",
    "    img = img.copy()\n",
    "    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n",
    "    return img\n",
    "\n",
    "\n",
    "def Equalize(img, **kwarg):\n",
    "    return PIL.ImageOps.equalize(img)\n",
    "\n",
    "\n",
    "def Identity(img, **kwarg):\n",
    "    return img\n",
    "\n",
    "\n",
    "def Invert(img, **kwarg):\n",
    "    return PIL.ImageOps.invert(img)\n",
    "\n",
    "\n",
    "def Posterize(img, v, max_v, bias=0):\n",
    "    v = _int_parameter(v, max_v) + bias\n",
    "    return PIL.ImageOps.posterize(img, v)\n",
    "\n",
    "\n",
    "def Rotate(img, v, max_v, bias=0):\n",
    "    v = _int_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    return img.rotate(v)\n",
    "\n",
    "\n",
    "def Sharpness(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n",
    "\n",
    "\n",
    "def ShearX(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n",
    "\n",
    "\n",
    "def ShearY(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n",
    "\n",
    "\n",
    "def Solarize(img, v, max_v, bias=0):\n",
    "    v = _int_parameter(v, max_v) + bias\n",
    "    return PIL.ImageOps.solarize(img, 256 - v)\n",
    "\n",
    "\n",
    "def SolarizeAdd(img, v, max_v, bias=0, threshold=128):\n",
    "    v = _int_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    img_np = np.array(img).astype(np.int)\n",
    "    img_np = img_np + v\n",
    "    img_np = np.clip(img_np, 0, 255)\n",
    "    img_np = img_np.astype(np.uint8)\n",
    "    img = Image.fromarray(img_np)\n",
    "    return PIL.ImageOps.solarize(img, threshold)\n",
    "\n",
    "\n",
    "def TranslateX(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    v = int(v * img.size[0])\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n",
    "\n",
    "\n",
    "def TranslateY(img, v, max_v, bias=0):\n",
    "    v = _float_parameter(v, max_v) + bias\n",
    "    if random.random() < 0.5:\n",
    "        v = -v\n",
    "    v = int(v * img.size[1])\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n",
    "\n",
    "\n",
    "def _float_parameter(v, max_v):\n",
    "    return float(v) * max_v / PARAMETER_MAX\n",
    "\n",
    "\n",
    "def _int_parameter(v, max_v):\n",
    "    return int(v * max_v / PARAMETER_MAX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandAugmentMC(object):\n",
    "    def __init__(self, n, m):\n",
    "        assert n >= 1\n",
    "        assert 1 <= m <= 10\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        self.augment_pool = fixmatch_augment_pool()\n",
    "\n",
    "    def __call__(self, img):\n",
    "        ops = random.choices(self.augment_pool, k=self.n)\n",
    "        for op, max_v, bias in ops:\n",
    "            v = np.random.randint(1, self.m)\n",
    "            if random.random() < 0.5:\n",
    "                img = op(img, v=v, max_v=max_v, bias=bias)\n",
    "        img = CutoutAbs(img, int(CFG['img_size']*0.5))\n",
    "        return img\n",
    "\n",
    "def fixmatch_augment_pool():\n",
    "    # FixMatch paper\n",
    "    augs = [(AutoContrast, None, None),\n",
    "            (Brightness, 0.9, 0.05),\n",
    "            (Color, 0.9, 0.05),\n",
    "            (Contrast, 0.9, 0.05),\n",
    "            (Equalize, None, None),\n",
    "            (Identity, None, None),\n",
    "            (Posterize, 4, 4),\n",
    "            (Rotate, 30, 0),\n",
    "            (Sharpness, 0.9, 0.05),\n",
    "            (ShearX, 0.3, 0),\n",
    "            (ShearY, 0.3, 0),\n",
    "            (Solarize, 256, 0),\n",
    "            (TranslateX, 0.3, 0),\n",
    "            (TranslateY, 0.3, 0)]\n",
    "    return augs\n",
    "\n",
    "class TransformFixMatch(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.weak = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(size=CFG['img_size'],\n",
    "                                  padding=int(CFG['img_size']*0.125),\n",
    "                                  padding_mode='reflect')])\n",
    "        self.strong = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(size=CFG['img_size'],\n",
    "                                  padding=int(CFG['img_size']*0.125),\n",
    "                                  padding_mode='reflect'),\n",
    "            RandAugmentMC(n=2, m=10)])\n",
    "        self.normalize = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        weak = self.weak(x)\n",
    "        strong = self.strong(x)\n",
    "        return self.normalize(weak), self.normalize(strong)\n",
    "\n",
    "\n",
    "class CassavaDataset_ul(Dataset):\n",
    "    def __init__(self, df, data_root, \n",
    "                 transforms=None, \n",
    "                 output_label=True, \n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transforms = transforms\n",
    "        self.data_root = data_root\n",
    "        \n",
    "        self.output_label = output_label\n",
    "        self.labels = self.df['label'].values\n",
    "\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # get labels\n",
    "        if self.output_label:\n",
    "            target = self.labels[index]\n",
    "          \n",
    "        img  = Image.open(\"{}/{}\".format(self.data_root, self.df.loc[index]['image_id']))\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        \n",
    "        if self.output_label == True:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "######################## 바꿔주자!!! 2019 데이터셋으로\n",
    "# unlabeled_dataset = CassavaDataset_ul(unlabeled, './input/cassava-disease/all', transforms=TransformFixMatch(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]))\n",
    "unlabeled_dataset = CassavaDataset_ul(unlabeled, './input/cassava-disease/all/', transforms=TransformFixMatch(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]))\n",
    "\n",
    "train_loader_ul = torch.utils.data.DataLoader(\n",
    "    unlabeled_dataset,\n",
    "    sampler = RandomSampler(unlabeled_dataset),\n",
    "    batch_size=CFG['train_bs'] * CFG['mu'],\n",
    "    pin_memory=False,\n",
    "    drop_last=True,     \n",
    "    num_workers=CFG['num_workers'],\n",
    ")\n",
    "\n",
    "def interleave(x, size):\n",
    "    s = list(x.shape)\n",
    "    return x.reshape([-1, size] + s[1:]).transpose(0, 1).reshape([-1] + s[1:])\n",
    "\n",
    "def de_interleave(x, size):\n",
    "    s = list(x.shape)\n",
    "    return x.reshape([size, -1] + s[1:]).transpose(0, 1).reshape([-1] + s[1:])\n",
    "\n",
    "\n",
    "# train_loader_ul = iter(train_loader_ul)\n",
    "# (inputs_u_w, inputs_u_s), _ = train_loader_ul.next()\n",
    "# print(len(inputs_u_s), len(inputs_u_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021054,
     "end_time": "2020-11-23T13:32:51.059722",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.038668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T13:32:51.129791Z",
     "iopub.status.busy": "2020-11-23T13:32:51.119346Z",
     "iopub.status.idle": "2020-11-23T13:32:51.143993Z",
     "shell.execute_reply": "2020-11-23T13:32:51.143192Z"
    },
    "papermill": {
     "duration": 0.061685,
     "end_time": "2020-11-23T13:32:51.144150",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.082465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_dataloader(df, trn_idx, val_idx, data_root='./input/cassava-leaf-disease-classification/train_images/'):\n",
    "    \n",
    "    # from catalyst.data.sampler import BalanceClassSampler\n",
    "    \n",
    "    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n",
    "    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n",
    "        \n",
    "    train_ds = CassavaDataset(train_, data_root, transforms=get_train_transforms(), output_label=True)\n",
    "    valid_ds = CassavaDataset(valid_, data_root, transforms=get_valid_transforms(), output_label=True)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        pin_memory=False,\n",
    "        drop_last=True,###\n",
    "        shuffle=True,        \n",
    "        num_workers=CFG['num_workers'],\n",
    "        #sampler=BalanceClassSampler(labels=train_['label'].values, mode=\"downsampling\")\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=CFG['valid_bs'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, unlabeled_trainloader, device, scheduler=None, swa_scheduler=None, schd_batch_update=False):\n",
    "    model.train()\n",
    "\n",
    "    t = time.time()\n",
    "    running_loss = None\n",
    "\n",
    "    # pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, image_labels) in enumerate(train_loader):\n",
    "        imgs = imgs.float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "\n",
    "        try:\n",
    "            (inputs_u_s, inputs_u_w), _ = unlabeled_iter.next()\n",
    "        except:\n",
    "            unlabeled_iter = iter(unlabeled_trainloader)\n",
    "            (inputs_u_s, inputs_u_w), _ = unlabeled_iter.next()\n",
    "\n",
    "        inputs = interleave(\n",
    "                torch.cat((imgs, inputs_u_w, inputs_u_s)), 2*CFG['mu']+1).contiguous().to(device)\n",
    "\n",
    "        with autocast():\n",
    "            image_preds = model(inputs)   #output = model(input)\n",
    "            logits = de_interleave(image_preds, 2*CFG['mu']+1)\n",
    "            logits_x = logits[:CFG['train_bs']]\n",
    "            logits_u_w, logits_u_s = logits[CFG['train_bs']:].chunk(2)\n",
    "            del logits\n",
    "\n",
    "            Lx = loss_fn(logits_x, image_labels)\n",
    "\n",
    "            pseudo_label = torch.softmax(logits_u_w.detach()/CFG['T'], dim=-1)\n",
    "            max_probs, targets_u = torch.max(pseudo_label, dim=-1)\n",
    "            mask = max_probs.ge(CFG['threshold']).float()\n",
    "\n",
    "#             Lu = (F.cross_entropy(logits_u_s, targets_u, reduction='none') * mask).mean()\n",
    "            Lu = (loss_fn(logits_u_s, targets_u, reduction='none')*mask).mean()\n",
    "            \n",
    "            loss = Lx + CFG['lambda_u'] * Lu\n",
    "            \n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if running_loss is None:\n",
    "                running_loss = loss.item()\n",
    "            else:\n",
    "                running_loss = running_loss * .99 + loss.item() * .01\n",
    "\n",
    "            if ((step + 1) %  CFG['accum_iter'] == 0) or ((step + 1) == len(train_loader)):\n",
    "\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad() \n",
    "                \n",
    "                if scheduler is not None and schd_batch_update:\n",
    "                    scheduler.step()\n",
    "\n",
    "            # if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "            #     description = f'epoch {epoch} loss: {running_loss:.4f}'\n",
    "            #     print(description)\n",
    "                # pbar.set_description(description)\n",
    "                \n",
    "    if scheduler is not None and not schd_batch_update:\n",
    "        if epoch >= CFG['swa_start_epoch']:\n",
    "            swa_scheduler.step()\n",
    "        else:\n",
    "            scheduler.step()\n",
    "        \n",
    "def valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n",
    "    model.eval()\n",
    "\n",
    "    t = time.time()\n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    \n",
    "    # pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    for step, (imgs, image_labels) in enumerate(val_loader):\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "        loss = loss_fn(image_preds, image_labels)\n",
    "        \n",
    "        loss_sum += loss.item()*image_labels.shape[0]\n",
    "        sample_num += image_labels.shape[0]  \n",
    "\n",
    "        # if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(val_loader)):\n",
    "        #     description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n",
    "        #     pbar.set_description(description)\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    print('epoch = {}'.format(epoch+1), 'validation multi-class accuracy = {:.4f}'.format((image_preds_all==image_targets_all).mean()))\n",
    "    \n",
    "    if scheduler is not None:\n",
    "        if schd_loss_update:\n",
    "            scheduler.step(loss_sum/sample_num)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "            \n",
    "def inference_one_epoch(model, data_loader, device):\n",
    "    model.eval()\n",
    "    image_preds_all = []\n",
    "    # pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    with torch.no_grad():\n",
    "        for step, (imgs, image_labels) in enumerate(data_loader):\n",
    "            imgs = imgs.to(device).float()\n",
    "\n",
    "            image_preds = model(imgs)   #output = model(input)\n",
    "            image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        \n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-23T13:32:51.197230Z",
     "iopub.status.busy": "2020-11-23T13:32:51.196427Z",
     "iopub.status.idle": "2020-11-23T13:32:51.200586Z",
     "shell.execute_reply": "2020-11-23T13:32:51.200056Z"
    },
    "papermill": {
     "duration": 0.034873,
     "end_time": "2020-11-23T13:32:51.200704",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.165831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reference: https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/173733\n",
    "class MyCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean'):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        lsm = F.log_softmax(inputs, -1)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            lsm = lsm * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = -(targets * lsm).sum(-1)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Label Smoothing\n",
    "# ====================================================\n",
    "class LabelSmoothingLoss(nn.Module): \n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1): \n",
    "        super(LabelSmoothingLoss, self).__init__() \n",
    "        self.confidence = 1.0 - smoothing \n",
    "        self.smoothing = smoothing \n",
    "        self.cls = classes \n",
    "        self.dim = dim \n",
    "        \n",
    "    def forward(self, pred, target, reduction = 'mean'): \n",
    "        pred = pred.log_softmax(dim=self.dim) \n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred) \n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1)) \n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence) \n",
    "        if reduction == 'mean':\n",
    "            return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n",
    "        else:\n",
    "            return torch.sum(-true_dist * pred, dim=self.dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020806,
     "end_time": "2020-11-23T13:32:51.243006",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.222200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # specify GPUs locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #debug\n",
    "# train = pd.read_csv('./input/cassava-leaf-disease-classification/train_debug.csv')\n",
    "# CFG['epochs']=7\n",
    "# model_path = 'temporary'\n",
    "# !mkdir -p temporary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='v2_hwkim_fixmatch_2019_fast_thr085_bs9_mu2_7ep_CusSwa4'\n",
    "# !mkdir -p v2_hwkim_fixmatch_2019_fast_thr085_bs9_mu2_7ep_CusSwa4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 0 started\n",
      "37 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004\n",
      "non swa\n",
      "epoch = 1 validation multi-class accuracy = 0.4000\n",
      "0.0003075\n",
      "non swa\n",
      "epoch = 2 validation multi-class accuracy = 0.5000\n",
      "0.00012250000000000005\n",
      "non swa\n",
      "epoch = 3 validation multi-class accuracy = 0.6000\n",
      "3e-05\n",
      "non swa\n",
      "epoch = 4 validation multi-class accuracy = 0.6000\n",
      "swa\n",
      "epoch = 4 validation multi-class accuracy = 0.6000\n",
      "3e-05\n",
      "non swa\n",
      "epoch = 5 validation multi-class accuracy = 0.6000\n",
      "swa\n",
      "epoch = 5 validation multi-class accuracy = 0.6000\n",
      "3e-05\n",
      "non swa\n",
      "epoch = 6 validation multi-class accuracy = 0.6000\n",
      "swa\n",
      "epoch = 6 validation multi-class accuracy = 0.6000\n",
      "3e-05\n",
      "non swa\n",
      "epoch = 7 validation multi-class accuracy = 0.6000\n",
      "swa\n",
      "epoch = 7 validation multi-class accuracy = 0.6000\n",
      "swa_BN\n",
      "epoch = 7 validation multi-class accuracy = 0.4000\n",
      "Training with 1 started\n",
      "37 10\n",
      "0.0004\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-063921ed1e34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munlabeled_trainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschd_batch_update\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'swa_start_epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'swa_start_epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-1e44aff5aab4>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch, model, loss_fn, optimizer, train_loader, unlabeled_trainloader, device, scheduler, swa_scheduler, schd_batch_update)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         inputs = interleave(\n\u001b[0;32m---> 47\u001b[0;31m                 torch.cat((imgs, inputs_u_w, inputs_u_s)), 2*CFG['mu']+1).contiguous().to(device)\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-a5fcdb2b8856>\u001b[0m in \u001b[0;36minterleave\u001b[0;34m(x, size)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minterleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mde_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    for c in range(5): \n",
    "        train[c] = 0\n",
    "        \n",
    "    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "        if fold<3:\n",
    "            continue\n",
    "        print('Training with {} started'.format(fold))\n",
    "        print(len(trn_idx), len(val_idx))\n",
    "        train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx, data_root='./input/cassava-leaf-disease-classification/train_images/')\n",
    "        unlabeled_trainloader = train_loader_ul\n",
    "        \n",
    "        device = torch.device(CFG['device'])\n",
    "\n",
    "        model = CassvaImgClassifier(CFG['model_arch'], train.label.nunique(), pretrained=True).to(device)\n",
    "\n",
    "        scaler = GradScaler()   \n",
    "        optimizer = AdamP(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CFG['swa_start_epoch']+1, T_mult=1, eta_min=CFG['min_lr'], last_epoch=-1)\n",
    "        swa_scheduler = SWALR(optimizer, swa_lr = CFG['min_lr'], anneal_epochs=1)\n",
    "\n",
    "        loss_tr = LabelSmoothingLoss(classes=CFG['target_size'], smoothing=CFG['smoothing']).to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "        for epoch in range(CFG['epochs']):\n",
    "            print(optimizer.param_groups[0][\"lr\"])\n",
    "            train_one_epoch(epoch, model, loss_tr, optimizer, train_loader, unlabeled_trainloader, device, scheduler=scheduler, swa_scheduler=swa_scheduler, schd_batch_update=False)\n",
    "            if epoch > CFG['swa_start_epoch']:\n",
    "                if epoch-1 == CFG['swa_start_epoch']:\n",
    "                    swa_model = AveragedModel(model,device='cpu').to(device)\n",
    "#                     update_bn(train_loader, swa_model, device=device)\n",
    "                else:\n",
    "                    swa_model.update_parameters(model)\n",
    "            with torch.no_grad():\n",
    "                print('non swa')\n",
    "                valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False)\n",
    "                if epoch > CFG['swa_start_epoch']:\n",
    "                    print('swa')\n",
    "                    valid_one_epoch(epoch, swa_model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False)\n",
    "            torch.save(model.state_dict(),'./'+model_path+'/{}_fold_{}_{}_{}'.format(CFG['model_arch'], fold, epoch, CFG['seed'])) \n",
    "        del unlabeled_trainloader, model\n",
    "        \n",
    "        with torch.no_grad():\n",
    "#             valid_one_epoch(epoch, swa_model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False)\n",
    "            torch.save(swa_model.module.state_dict(),'./'+model_path+'/noBN_swa_{}_fold_{}_{}'.format(CFG['model_arch'], fold, epoch))\n",
    "#             print('swa_BN')\n",
    "#             update_bn(train_loader, swa_model, device=device)\n",
    "#             valid_one_epoch(epoch, swa_model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False)\n",
    "#             torch.save(swa_model.state_dict(),'./'+model_path+'/BN_swa_{}_fold_{}_{}'.format(CFG['model_arch'], fold, epoch)) \n",
    "        \n",
    "        tst_preds = []\n",
    "        for tta in range(5):\n",
    "            tst_preds += [inference_one_epoch(swa_model, val_loader, device)]\n",
    "        \n",
    "        train.loc[val_idx, [0, 1, 2, 3, 4]] = np.mean(tst_preds, axis=0)\n",
    "        \n",
    "        del swa_model, optimizer, train_loader, val_loader, scaler, scheduler\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    train['pred'] = np.array(train[[0, 1, 2, 3, 4]]).argmax(axis=1)\n",
    "    print(accuracy_score(train['label'].values, train['pred'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "duration": 8637.721674,
   "end_time": "2020-11-23T15:56:40.428882",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-23T13:32:42.707208",
   "version": "2.1.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
