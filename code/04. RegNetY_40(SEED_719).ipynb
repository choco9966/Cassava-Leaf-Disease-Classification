{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04. RegNetY_40(SEED 719)",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzstaI-WRcQU"
      },
      "source": [
        "import os\r\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '2' # specify GPUs locally"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l9Vp64oRs2R"
      },
      "source": [
        "package_paths = [\r\n",
        "    './input/pytorch-image-models/pytorch-image-models-master', #'../input/efficientnet-pytorch-07/efficientnet_pytorch-0.7.0'\r\n",
        "    './input/pytorch-gradual-warmup-lr-master'\r\n",
        "]\r\n",
        "import sys; \r\n",
        "\r\n",
        "for pth in package_paths:\r\n",
        "    sys.path.append(pth)\r\n",
        "    \r\n",
        "from warmup_scheduler import GradualWarmupScheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3Zj9ikhRt54"
      },
      "source": [
        "from glob import glob\r\n",
        "from sklearn.model_selection import GroupKFold, StratifiedKFold\r\n",
        "import cv2\r\n",
        "from skimage import io\r\n",
        "import torch\r\n",
        "from torch import nn\r\n",
        "import os\r\n",
        "from datetime import datetime\r\n",
        "import time\r\n",
        "import random\r\n",
        "import cv2\r\n",
        "import torchvision\r\n",
        "from torchvision import transforms\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torch.utils.data import Dataset,DataLoader\r\n",
        "from torch.utils.data.sampler import SequentialSampler, RandomSampler\r\n",
        "from torch.cuda.amp import autocast, GradScaler\r\n",
        "from torch.nn.modules.loss import _WeightedLoss\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "import timm\r\n",
        "\r\n",
        "import sklearn\r\n",
        "import warnings\r\n",
        "import joblib\r\n",
        "from sklearn.metrics import roc_auc_score, log_loss\r\n",
        "from sklearn import metrics\r\n",
        "import warnings\r\n",
        "import cv2\r\n",
        "#from efficientnet_pytorch import EfficientNet\r\n",
        "from scipy.ndimage.interpolation import zoom"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3QHoDCkRvOY"
      },
      "source": [
        "CFG = {\r\n",
        "    'fold_num': 5,\r\n",
        "    'seed': 719,\r\n",
        "    'model_arch': 'regnety_040',\r\n",
        "    'model_path' : 'regnety_040_bs24_epoch20_reset_swalr_step',\r\n",
        "    'img_size': 512,\r\n",
        "    'epochs': 20,\r\n",
        "    'train_bs': 24,\r\n",
        "    'valid_bs': 8,\r\n",
        "    'T_0': 10,\r\n",
        "    'lr': 1e-4,\r\n",
        "    'min_lr': 1e-6,\r\n",
        "    'weight_decay':1e-6,\r\n",
        "    'num_workers': 4,\r\n",
        "    'accum_iter': 1, # suppoprt to do batch accumulation for backprop with effectively larger batch size\r\n",
        "    'verbose_step': 1,\r\n",
        "    'device': 'cuda:0',\r\n",
        "    'target_size' : 5, \r\n",
        "    'smoothing' : 0.2\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYgIGZZIRvQQ"
      },
      "source": [
        "if not os.path.isdir(CFG['model_path']):\r\n",
        "    os.mkdir(CFG['model_path'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0Sf0o8FRvSQ"
      },
      "source": [
        "train = pd.read_csv('./../input/cassava-leaf-disease-classification/train.csv')\r\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cxmisO1RvUQ"
      },
      "source": [
        "submission = pd.read_csv('./../input/cassava-leaf-disease-classification/sample_submission.csv')\r\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMyJ_YTuRvWI"
      },
      "source": [
        "def seed_everything(seed):\r\n",
        "    random.seed(seed)\r\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\r\n",
        "    np.random.seed(seed)\r\n",
        "    torch.manual_seed(seed)\r\n",
        "    torch.cuda.manual_seed(seed)\r\n",
        "    torch.backends.cudnn.deterministic = True\r\n",
        "    torch.backends.cudnn.benchmark = False\r\n",
        "    \r\n",
        "def get_img(path):\r\n",
        "    im_bgr = cv2.imread(path)\r\n",
        "    im_rgb = im_bgr[:, :, ::-1]\r\n",
        "    #print(im_rgb)\r\n",
        "    return im_rgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAE9Bb24R0O4"
      },
      "source": [
        "def rand_bbox(size, lam):\r\n",
        "    W = size[0]\r\n",
        "    H = size[1]\r\n",
        "    cut_rat = np.sqrt(1. - lam)\r\n",
        "    cut_w = np.int(W * cut_rat)\r\n",
        "    cut_h = np.int(H * cut_rat)\r\n",
        "\r\n",
        "    # uniform\r\n",
        "    cx = np.random.randint(W)\r\n",
        "    cy = np.random.randint(H)\r\n",
        "\r\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\r\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\r\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\r\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\r\n",
        "    return bbx1, bby1, bbx2, bby2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNUKSfrPR0Q5"
      },
      "source": [
        "class CassavaDataset(Dataset):\r\n",
        "    def __init__(self, df, data_root, \r\n",
        "                 transforms=None, \r\n",
        "                 output_label=True, \r\n",
        "                ):\r\n",
        "        \r\n",
        "        super().__init__()\r\n",
        "        self.df = df.reset_index(drop=True).copy()\r\n",
        "        self.transforms = transforms\r\n",
        "        self.data_root = data_root\r\n",
        "        \r\n",
        "        self.output_label = output_label\r\n",
        "        self.labels = self.df['label'].values\r\n",
        "\r\n",
        "            \r\n",
        "    def __len__(self):\r\n",
        "        return self.df.shape[0]\r\n",
        "    \r\n",
        "    def __getitem__(self, index: int):\r\n",
        "        \r\n",
        "        # get labels\r\n",
        "        if self.output_label:\r\n",
        "            target = self.labels[index]\r\n",
        "          \r\n",
        "        img  = get_img(\"{}/{}\".format(self.data_root, self.df.loc[index]['image_id']))\r\n",
        "\r\n",
        "        if self.transforms:\r\n",
        "            img = self.transforms(image=img)['image']\r\n",
        "        \r\n",
        "        if self.output_label == True:\r\n",
        "            return img, target\r\n",
        "        else:\r\n",
        "            return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Airm8ozR0TA"
      },
      "source": [
        "from albumentations.core.transforms_interface import DualTransform\r\n",
        "from albumentations.augmentations import functional as F\r\n",
        "class GridMask(DualTransform):\r\n",
        "    \"\"\"GridMask augmentation for image classification and object detection.\r\n",
        "    \r\n",
        "    Author: Qishen Ha\r\n",
        "    Email: haqishen@gmail.com\r\n",
        "    2020/01/29\r\n",
        "    Args:\r\n",
        "        num_grid (int): number of grid in a row or column.\r\n",
        "        fill_value (int, float, lisf of int, list of float): value for dropped pixels.\r\n",
        "        rotate ((int, int) or int): range from which a random angle is picked. If rotate is a single int\r\n",
        "            an angle is picked from (-rotate, rotate). Default: (-90, 90)\r\n",
        "        mode (int):\r\n",
        "            0 - cropout a quarter of the square of each grid (left top)\r\n",
        "            1 - reserve a quarter of the square of each grid (left top)\r\n",
        "            2 - cropout 2 quarter of the square of each grid (left top & right bottom)\r\n",
        "    Targets:\r\n",
        "        image, mask\r\n",
        "    Image types:\r\n",
        "        uint8, float32\r\n",
        "    Reference:\r\n",
        "    |  https://arxiv.org/abs/2001.04086\r\n",
        "    |  https://github.com/akuxcw/GridMask\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, num_grid=3, fill_value=0, rotate=0, mode=0, always_apply=False, p=0.5):\r\n",
        "        super(GridMask, self).__init__(always_apply, p)\r\n",
        "        if isinstance(num_grid, int):\r\n",
        "            num_grid = (num_grid, num_grid)\r\n",
        "        if isinstance(rotate, int):\r\n",
        "            rotate = (-rotate, rotate)\r\n",
        "        self.num_grid = num_grid\r\n",
        "        self.fill_value = fill_value\r\n",
        "        self.rotate = rotate\r\n",
        "        self.mode = mode\r\n",
        "        self.masks = None\r\n",
        "        self.rand_h_max = []\r\n",
        "        self.rand_w_max = []\r\n",
        "\r\n",
        "    def init_masks(self, height, width):\r\n",
        "        if self.masks is None:\r\n",
        "            self.masks = []\r\n",
        "            n_masks = self.num_grid[1] - self.num_grid[0] + 1\r\n",
        "            for n, n_g in enumerate(range(self.num_grid[0], self.num_grid[1] + 1, 1)):\r\n",
        "                grid_h = height / n_g\r\n",
        "                grid_w = width / n_g\r\n",
        "                this_mask = np.ones((int((n_g + 1) * grid_h), int((n_g + 1) * grid_w))).astype(np.uint8)\r\n",
        "                for i in range(n_g + 1):\r\n",
        "                    for j in range(n_g + 1):\r\n",
        "                        this_mask[\r\n",
        "                             int(i * grid_h) : int(i * grid_h + grid_h / 2),\r\n",
        "                             int(j * grid_w) : int(j * grid_w + grid_w / 2)\r\n",
        "                        ] = self.fill_value\r\n",
        "                        if self.mode == 2:\r\n",
        "                            this_mask[\r\n",
        "                                 int(i * grid_h + grid_h / 2) : int(i * grid_h + grid_h),\r\n",
        "                                 int(j * grid_w + grid_w / 2) : int(j * grid_w + grid_w)\r\n",
        "                            ] = self.fill_value\r\n",
        "                \r\n",
        "                if self.mode == 1:\r\n",
        "                    this_mask = 1 - this_mask\r\n",
        "\r\n",
        "                self.masks.append(this_mask)\r\n",
        "                self.rand_h_max.append(grid_h)\r\n",
        "                self.rand_w_max.append(grid_w)\r\n",
        "\r\n",
        "    def apply(self, image, mask, rand_h, rand_w, angle, **params):\r\n",
        "        h, w = image.shape[:2]\r\n",
        "        mask = F.rotate(mask, angle) if self.rotate[1] > 0 else mask\r\n",
        "        mask = mask[:,:,np.newaxis] if image.ndim == 3 else mask\r\n",
        "        image *= mask[rand_h:rand_h+h, rand_w:rand_w+w].astype(image.dtype)\r\n",
        "        return image\r\n",
        "\r\n",
        "    def get_params_dependent_on_targets(self, params):\r\n",
        "        img = params['image']\r\n",
        "        height, width = img.shape[:2]\r\n",
        "        self.init_masks(height, width)\r\n",
        "\r\n",
        "        mid = np.random.randint(len(self.masks))\r\n",
        "        mask = self.masks[mid]\r\n",
        "        rand_h = np.random.randint(self.rand_h_max[mid])\r\n",
        "        rand_w = np.random.randint(self.rand_w_max[mid])\r\n",
        "        angle = np.random.randint(self.rotate[0], self.rotate[1]) if self.rotate[1] > 0 else 0\r\n",
        "\r\n",
        "        return {'mask': mask, 'rand_h': rand_h, 'rand_w': rand_w, 'angle': angle}\r\n",
        "\r\n",
        "    @property\r\n",
        "    def targets_as_params(self):\r\n",
        "        return ['image']\r\n",
        "\r\n",
        "    def get_transform_init_args_names(self):\r\n",
        "        return ('num_grid', 'fill_value', 'rotate', 'mode')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3JvnwzmR0VA"
      },
      "source": [
        "from albumentations import (\r\n",
        "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\r\n",
        "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\r\n",
        "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\r\n",
        "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\r\n",
        ")\r\n",
        "\r\n",
        "from albumentations.pytorch import ToTensorV2\r\n",
        "\r\n",
        "def get_train_transforms():\r\n",
        "    return Compose([\r\n",
        "            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\r\n",
        "            Transpose(p=0.5),\r\n",
        "            HorizontalFlip(p=0.5),\r\n",
        "            #VerticalFlip(p=0.5),\r\n",
        "            ShiftScaleRotate(p=0.5),\r\n",
        "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\r\n",
        "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\r\n",
        "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\r\n",
        "            CoarseDropout(p=0.5),\r\n",
        "            GridMask(num_grid=3, p=0.5),\r\n",
        "            ToTensorV2(p=1.0),\r\n",
        "        ], p=1.)\r\n",
        "  \r\n",
        "        \r\n",
        "def get_valid_transforms():\r\n",
        "    return Compose([\r\n",
        "            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\r\n",
        "            Resize(CFG['img_size'], CFG['img_size']),\r\n",
        "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\r\n",
        "            ToTensorV2(p=1.0),\r\n",
        "        ], p=1.)\r\n",
        "\r\n",
        "def get_inference_transforms():\r\n",
        "    return Compose([\r\n",
        "            OneOf([\r\n",
        "                Resize(CFG['img_size'], CFG['img_size'], p=1.),\r\n",
        "                CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\r\n",
        "                RandomResizedCrop(CFG['img_size'], CFG['img_size'], p=1.)\r\n",
        "            ], p=1.), \r\n",
        "            Transpose(p=0.5),\r\n",
        "            HorizontalFlip(p=0.5),\r\n",
        "            #VerticalFlip(p=0.5),\r\n",
        "            Resize(CFG['img_size'], CFG['img_size']),\r\n",
        "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\r\n",
        "            ToTensorV2(p=1.0),\r\n",
        "        ], p=1.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kha1Y_q4R0XQ"
      },
      "source": [
        "class CassvaImgClassifier(nn.Module):\r\n",
        "    def __init__(self, model_arch, n_class, pretrained=False):\r\n",
        "        super().__init__()\r\n",
        "        self.model = timm.create_model(model_arch, pretrained=pretrained)\r\n",
        "        if model_arch == 'regnety_040':\r\n",
        "            self.model.head = nn.Sequential(\r\n",
        "                                nn.AdaptiveAvgPool2d((1,1)),\r\n",
        "                                nn.Flatten(),\r\n",
        "                                nn.Linear(1088, n_class)\r\n",
        "            )\r\n",
        "        elif model_arch == 'regnety_320':\r\n",
        "            self.model.head = nn.Sequential(\r\n",
        "                                nn.AdaptiveAvgPool2d((1,1)),\r\n",
        "                                nn.Flatten(),\r\n",
        "                                nn.Linear(3712, n_class)\r\n",
        "            )\r\n",
        "        elif model_arch == 'regnety_080':\r\n",
        "            self.model.head = nn.Sequential(\r\n",
        "                                nn.AdaptiveAvgPool2d((1,1)),\r\n",
        "                                nn.Flatten(),\r\n",
        "                                nn.Linear(2016, n_class)\r\n",
        "            )\r\n",
        "            \r\n",
        "        elif model_arch == 'regnety_160':\r\n",
        "            self.model.head = nn.Sequential(\r\n",
        "                                nn.AdaptiveAvgPool2d((1,1)),\r\n",
        "                                nn.Flatten(),\r\n",
        "                                nn.Linear(3024, n_class)\r\n",
        "            )\r\n",
        "            \r\n",
        "        else:\r\n",
        "            n_features = self.model.classifier.in_features\r\n",
        "            self.model.classifier = nn.Linear(n_features, n_class)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.model(x)\r\n",
        "        return x\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G53rvCxxR0ZY"
      },
      "source": [
        "def prepare_dataloader(df, trn_idx, val_idx, data_root='./input/cassava-leaf-disease-classification/train_images/'):\r\n",
        "    \r\n",
        "    # from catalyst.data.sampler import BalanceClassSampler\r\n",
        "    \r\n",
        "    train_ = df.loc[trn_idx,:].reset_index(drop=True)\r\n",
        "    valid_ = df.loc[val_idx,:].reset_index(drop=True)\r\n",
        "        \r\n",
        "    train_ds = CassavaDataset(train_, data_root, transforms=get_train_transforms(), output_label=True)\r\n",
        "    valid_ds = CassavaDataset(valid_, data_root, transforms=get_valid_transforms(), output_label=True)\r\n",
        "    \r\n",
        "    train_loader = torch.utils.data.DataLoader(\r\n",
        "        train_ds,\r\n",
        "        batch_size=CFG['train_bs'],\r\n",
        "        pin_memory=False,\r\n",
        "        drop_last=False,\r\n",
        "        shuffle=True,        \r\n",
        "        num_workers=CFG['num_workers'],\r\n",
        "        #sampler=BalanceClassSampler(labels=train_['label'].values, mode=\"downsampling\")\r\n",
        "    )\r\n",
        "    val_loader = torch.utils.data.DataLoader(\r\n",
        "        valid_ds, \r\n",
        "        batch_size=CFG['valid_bs'],\r\n",
        "        num_workers=CFG['num_workers'],\r\n",
        "        shuffle=False,\r\n",
        "        pin_memory=False,\r\n",
        "    )\r\n",
        "    return train_loader, val_loader\r\n",
        "\r\n",
        "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None, schd_batch_update=False):\r\n",
        "    model.train()\r\n",
        "\r\n",
        "    t = time.time()\r\n",
        "    running_loss = None\r\n",
        "\r\n",
        "    # pbar = tqdm(enumerate(train_loader), total=len(train_loader))\r\n",
        "    for step, (imgs, image_labels) in enumerate(train_loader):\r\n",
        "        imgs = imgs.to(device).float()\r\n",
        "        image_labels = image_labels.to(device).long()\r\n",
        "\r\n",
        "        with autocast():\r\n",
        "            image_preds = model(imgs)   #output = model(input)\r\n",
        "            loss = loss_fn(image_preds, image_labels)\r\n",
        "            \r\n",
        "            scaler.scale(loss).backward()\r\n",
        "\r\n",
        "            if running_loss is None:\r\n",
        "                running_loss = loss.item()\r\n",
        "            else:\r\n",
        "                running_loss = running_loss * .99 + loss.item() * .01\r\n",
        "\r\n",
        "            if ((step + 1) %  CFG['accum_iter'] == 0) or ((step + 1) == len(train_loader)):\r\n",
        "\r\n",
        "                scaler.step(optimizer)\r\n",
        "                scaler.update()\r\n",
        "                optimizer.zero_grad() \r\n",
        "                \r\n",
        "                if scheduler is not None and schd_batch_update:\r\n",
        "                    scheduler.step()\r\n",
        "\r\n",
        "            # if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\r\n",
        "            #     description = f'epoch {epoch} loss: {running_loss:.4f}'\r\n",
        "            #     print(description)\r\n",
        "                # pbar.set_description(description)\r\n",
        "                \r\n",
        "    if scheduler is not None and not schd_batch_update:\r\n",
        "        scheduler.step()\r\n",
        "        \r\n",
        "def valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    t = time.time()\r\n",
        "    loss_sum = 0\r\n",
        "    sample_num = 0\r\n",
        "    image_preds_all = []\r\n",
        "    image_targets_all = []\r\n",
        "    \r\n",
        "    # pbar = tqdm(enumerate(val_loader), total=len(val_loader))\r\n",
        "    for step, (imgs, image_labels) in enumerate(val_loader):\r\n",
        "        imgs = imgs.to(device).float()\r\n",
        "        image_labels = image_labels.to(device).long()\r\n",
        "        \r\n",
        "        image_preds = model(imgs)   #output = model(input)\r\n",
        "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\r\n",
        "        image_targets_all += [image_labels.detach().cpu().numpy()]\r\n",
        "        \r\n",
        "        loss = loss_fn(image_preds, image_labels)\r\n",
        "        \r\n",
        "        loss_sum += loss.item()*image_labels.shape[0]\r\n",
        "        sample_num += image_labels.shape[0]  \r\n",
        "\r\n",
        "        # if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(val_loader)):\r\n",
        "        #     description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\r\n",
        "        #     pbar.set_description(description)\r\n",
        "    \r\n",
        "    image_preds_all = np.concatenate(image_preds_all)\r\n",
        "    image_targets_all = np.concatenate(image_targets_all)\r\n",
        "    print('epoch = {}'.format(epoch+1), 'validation multi-class accuracy = {:.4f}'.format((image_preds_all==image_targets_all).mean()))\r\n",
        "    \r\n",
        "    if scheduler is not None:\r\n",
        "        if schd_loss_update:\r\n",
        "            scheduler.step(loss_sum/sample_num)\r\n",
        "        else:\r\n",
        "            scheduler.step()\r\n",
        "        \r\n",
        "def inference_one_epoch(model, data_loader, device):\r\n",
        "    model.eval()\r\n",
        "    image_preds_all = []\r\n",
        "    # pbar = tqdm(enumerate(data_loader), total=len(data_loader))\r\n",
        "    with torch.no_grad():\r\n",
        "        for step, (imgs, _labels) in enumerate(data_loader):\r\n",
        "            imgs = imgs.to(device).float()\r\n",
        "\r\n",
        "            image_preds = model(imgs)   #output = model(input)\r\n",
        "            image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\r\n",
        "        \r\n",
        "    \r\n",
        "    image_preds_all = np.concatenate(image_preds_all, axis=0)\r\n",
        "    return image_preds_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBJrLJ8UR0bo"
      },
      "source": [
        "# reference: https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/173733\r\n",
        "class MyCrossEntropyLoss(_WeightedLoss):\r\n",
        "    def __init__(self, weight=None, reduction='mean'):\r\n",
        "        super().__init__(weight=weight, reduction=reduction)\r\n",
        "        self.weight = weight\r\n",
        "        self.reduction = reduction\r\n",
        "\r\n",
        "    def forward(self, inputs, targets):\r\n",
        "        lsm = F.log_softmax(inputs, -1)\r\n",
        "\r\n",
        "        if self.weight is not None:\r\n",
        "            lsm = lsm * self.weight.unsqueeze(0)\r\n",
        "\r\n",
        "        loss = -(targets * lsm).sum(-1)\r\n",
        "\r\n",
        "        if  self.reduction == 'sum':\r\n",
        "            loss = loss.sum()\r\n",
        "        elif  self.reduction == 'mean':\r\n",
        "            loss = loss.mean()\r\n",
        "\r\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuJNXRQ5R0d5"
      },
      "source": [
        "# ====================================================\r\n",
        "# Label Smoothing\r\n",
        "# ====================================================\r\n",
        "class LabelSmoothingLoss(nn.Module): \r\n",
        "    def __init__(self, classes, smoothing=0.0, dim=-1): \r\n",
        "        super(LabelSmoothingLoss, self).__init__() \r\n",
        "        self.confidence = 1.0 - smoothing \r\n",
        "        self.smoothing = smoothing \r\n",
        "        self.cls = classes \r\n",
        "        self.dim = dim \r\n",
        "        \r\n",
        "    def forward(self, pred, target): \r\n",
        "        pred = pred.log_softmax(dim=self.dim) \r\n",
        "        with torch.no_grad():\r\n",
        "            true_dist = torch.zeros_like(pred) \r\n",
        "            true_dist.fill_(self.smoothing / (self.cls - 1)) \r\n",
        "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence) \r\n",
        "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOxHCGJvR0gR"
      },
      "source": [
        "from torchcontrib.optim import SWA\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    for c in range(5): \r\n",
        "        train[c] = 0\r\n",
        "        \r\n",
        "    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\r\n",
        "    for fold, (trn_idx, val_idx) in enumerate(folds):\r\n",
        "        print('Training with {} started'.format(fold))\r\n",
        "        print(len(trn_idx), len(val_idx))\r\n",
        "        train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx, data_root='./../input/cassava-leaf-disease-classification/train_images/')\r\n",
        "\r\n",
        "        device = torch.device(CFG['device'])\r\n",
        "\r\n",
        "        model = CassvaImgClassifier(CFG['model_arch'], train.label.nunique(), pretrained=True).to(device)\r\n",
        "#         model = BotNet(train.label.nunique()).to(device)\r\n",
        "        \r\n",
        "        scaler = GradScaler()   \r\n",
        "        base_opt = torch.optim.Adam(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\r\n",
        "        optimizer = SWA(base_opt, swa_start=2*len(trn_idx)//CFG['train_bs'], swa_freq=len(trn_idx)//CFG['train_bs'])\r\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CFG['T_0'], T_mult=1, eta_min=CFG['min_lr'], last_epoch=-1)\r\n",
        "\r\n",
        "        loss_tr = LabelSmoothingLoss(classes=CFG['target_size'], smoothing=CFG['smoothing']).to(device)\r\n",
        "        loss_fn = nn.CrossEntropyLoss().to(device)\r\n",
        "\r\n",
        "        for epoch in range(CFG['epochs']):\r\n",
        "            train_one_epoch(epoch, model, loss_tr, optimizer, train_loader, device, scheduler=scheduler, schd_batch_update=False)\r\n",
        "\r\n",
        "            with torch.no_grad():\r\n",
        "                valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False)\r\n",
        "            # torch.save(model.state_dict(),'./model9_2/{}_fold_{}_{}_{}'.format(CFG['model_arch'], fold, epoch, seed)) \r\n",
        "        optimizer.swap_swa_sgd()\r\n",
        "        optimizer.bn_update(train_loader, model, device)\r\n",
        "\r\n",
        "        with torch.no_grad():\r\n",
        "            valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False)\r\n",
        "            torch.save(model.state_dict(),'./{}/swa_{}_fold_{}_{}'.format(CFG['model_path'],CFG['model_arch'], fold, epoch)) \r\n",
        "        \r\n",
        "        tst_preds = []\r\n",
        "        for tta in range(5):\r\n",
        "            tst_preds += [inference_one_epoch(model, val_loader, device)]\r\n",
        "        \r\n",
        "        train.loc[val_idx, [0, 1, 2, 3, 4]] = np.mean(tst_preds, axis=0)\r\n",
        "        \r\n",
        "        del model, optimizer, train_loader, val_loader, scaler, scheduler\r\n",
        "        torch.cuda.empty_cache()\r\n",
        "    \r\n",
        "    train['pred'] = np.array(train[[0, 1, 2, 3, 4]]).argmax(axis=1)\r\n",
        "    print(accuracy_score(train['label'].values, train['pred'].values))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}